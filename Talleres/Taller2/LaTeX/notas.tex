\documentclass[12pt]{article}\usepackage[]{graphicx}\usepackage[]{xcolor}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlsng}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hldef}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}
\usepackage[spanish]{babel}
\usepackage{xurl}
\usepackage{tcolorbox}
\usepackage{titlesec}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage{cancel}
\usepackage[hidelinks]{hyperref}

\titleclass{\subsubsubsection}{straight}[\subsection]

\newcounter{subsubsubsection}[subsubsection]
\renewcommand\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}
\renewcommand\theparagraph{\thesubsubsubsection.\arabic{paragraph}} % optional; useful if paragraphs are to be numbered

\titleformat{\subsubsubsection}
{\normalfont\normalsize\bfseries}{\thesubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsection}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{5}{\z@}%
  {3.25ex \@plus1ex \@minus.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\renewcommand\subparagraph{\@startsection{subparagraph}{6}{\parindent}%
  {3.25ex \@plus1ex \@minus .2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\def\toclevel@subsubsubsection{4}
\def\toclevel@paragraph{5}
% \def\toclevel@paragraph{6}
\def\toclevel@subparagraph{6}
\def\l@subsubsubsection{\@dottedtocline{4}{7em}{4em}}
\def\l@paragraph{\@dottedtocline{5}{10em}{5em}}
\def\l@subparagraph{\@dottedtocline{6}{14em}{6em}}
\makeatother

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

% Set up headers and footers
\pagestyle{fancy}
\fancyhf{}  % Clear previous settings

\fancyhead[L]{Julián - Ludwig}
\fancyhead[C]{Taller 2 - Sim Estocástica}
\fancyhead[R]{\today}

\fancyfoot[C]{\thepage}
\fancyfoot[C]{\footnotesize Este trabajo está bajo una licencia CC BY-SA 4.0. Más info: \url{https://creativecommons.org/licenses/by/4.0/}}

\renewcommand{\headrulewidth}{0.2pt}


% Define R Style for listings
\lstdefinestyle{RStyle}{
  language=R,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue}\bfseries,
  commentstyle=\color{green!40!black}\itshape,
  stringstyle=\color{red!70!black},
  numbers=left,
  numberstyle=\tiny\color{gray},
  stepnumber=1,
  numbersep=5pt,
  backgroundcolor=\color{gray!10},
  showstringspaces=false,
  breaklines=true,
  frame=single,
  rulecolor=\color{black},
  captionpos=b,
  morekeywords={generator}
}

% Set RStyle as default
\lstset{style=RStyle}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}


\section{Stopping generating new simulation data}

Write a program to generate standard normal random variables until you have generated n of them, where $n \geq 100$ is such that $S/\sqrt{n} < 0.01$, where S is the sample standard deviation of the n data values. Note that this is the ``Method for Determining When to Stop Generating New Data''. Also, answer the following questions:



Debido a que se va a generar variables aleatorias \textbf{normales estándar} $X_{i}$, es decir, $X_{i} \sim \mathcal{N}(0, 1)$ y se debe parar de generar cuando $\frac{S}{\sqrt{n}} < 0.01$.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{x} \hlkwb{<-} \hlkwd{numeric}\hldef{()}
\hldef{s} \hlkwb{<-} \hlnum{1}
\hldef{n} \hlkwb{<-} \hlnum{0}

\hlkwa{while}\hldef{(n} \hlopt{<} \hlnum{100} \hlopt{||} \hldef{s} \hlopt{/} \hlkwd{sqrt}\hldef{(n)} \hlopt{>=} \hlnum{0.01}\hldef{) \{}
  \hldef{x} \hlkwb{<-} \hlkwd{c}\hldef{(x,} \hlkwd{rnorm}\hldef{(}\hlnum{1}\hldef{))}
  \hldef{n} \hlkwb{<-} \hlkwd{length}\hldef{(x)}
  \hldef{s} \hlkwb{<-} \hlkwd{sd}\hldef{(x)}
\hldef{\}}

\hlkwd{cat}\hldef{(}\hlsng{"Cantidad de Xi generados"}\hldef{, n,} \hlsng{"\textbackslash{}n"}\hldef{)}
\end{alltt}
\begin{verbatim}
## Cantidad de Xi generados 9866
\end{verbatim}
\begin{alltt}
\hlkwd{cat}\hldef{(}\hlsng{"Desviación estándar"}\hldef{,} \hlkwd{round}\hldef{(s,} \hlnum{5}\hldef{),} \hlsng{"\textbackslash{}n"}\hldef{)}
\end{alltt}
\begin{verbatim}
## Desviación estándar 0.99325
\end{verbatim}
\begin{alltt}
\hlkwd{cat}\hldef{(}\hlsng{"Error estándar S/sqrt(n)"}\hldef{,} \hlkwd{round}\hldef{(s}\hlopt{/}\hlkwd{sqrt}\hldef{(n),} \hlnum{5}\hldef{),} \hlsng{"\textbackslash{}n"}\hldef{)}
\end{alltt}
\begin{verbatim}
## Error estándar S/sqrt(n) 0.01
\end{verbatim}
\end{kframe}
\end{knitrout}


En el código se declara una variable $s$ inicializada en 1 para que luego sea nuevamente computada a la desviación estándar de $x$ que es un vector que va a almacenar todas las variables normales aleatorias generadas. Según el enunciado tenemos una condición de que al menos deben haber 100 variables aleatorias generadas ($n \geq 100$) y que el error estándar sea menor a 0.01 ($S / \sqrt{n} < 0.01$). En el ciclo \lstinline|while|, por lo tanto, tiene sentido que el ciclo continue si alguna de las afirmaciones anteriores son falsas, por eso queda la condición de esa manera. Se hace uso de la función \lstinline|rnorm(1)| para que genere una variable aleatoria normal con los valores por defecto (promedio 0 y desviación 1). 






\subsection{How many normals do you think will be generated? Give an analytic estimate.}
\label{subsec:p1-a}

\subsubsection{Respuesta}

Aunque ya se tengan los resultados de la simulación, se puede hacer un estimado analítico con la condición $S / \sqrt{n} < 0.01$ donde se puede despejar $n$ para saber cuántas variables se necesitan para parar el criterio.

Se tiene en primer lugar la inecuación:

\[
\frac{S}{\sqrt{n}} < 0.01
\]

Se eleva ambas partes con menos 1:

\begin{align*}
  \left(\frac{S}{\sqrt{n}}  \right)^{-1} &> 0.01^{-1} \\
  \frac{\sqrt{n}}{S}  &> 100
\end{align*}

Multiplicando ambas partes por $S$:

\begin{align*}
  \cancel{S} \times \frac{\sqrt{n}}{\cancel{S}}  &> 100 \times S \\
  \sqrt{n} &> 100 \times S 
\end{align*}

Ahora se cancela la raíz elevando ambas partes al cuadrado:

\begin{align*}
  (\cancel{\sqrt{n}})^{\cancel{2}} &> (100 \times S)^{2} 
\end{align*}

Quedando entonces:

\[
n > 10000\times S^{2}
\]

Para hacer el ejercicio se utilizó en \textsf{R} la función \texttt{rnorm(1, mean = 0, sd = 1)}, de esta manera genera únicamente 1 valor con media 0 y desviación 1, por lo tanto, podemos hacer $S = 1$ para estimar cuántos $n$ necesitamos para que se cumpla condición y deje de generar variables aleatorias, por lo tanto:

\begin{align*}
  n &> 10000 \times (1)^{2} \\
  n &> 10000 
\end{align*}

Este valor se acerca bastante al que se imprime en la simulación. 











\subsection{How many normals did you generate?}
\label{subsec:p1-b}

\subsubsection{Respuesta}

Se han generado \lstinline|n=| $9866$ normales.


\subsection{What is the sample mean of all the normals generated?}
\label{subsec:p1-c}




\subsubsection{Respuesta}

Utilizando el comando \lstinline|mean()| al vector \lstinline|x| se obtiene $-0.0160261$. 

\subsection{What is the sample variance?}
\label{subsec:p1-d}


\subsubsection{Respuesta}

La varianza muestral se calcula como:

\[
S^{2} = \frac{\sum_{i=1}^{n} (X_{i} - \bar{X})^{2}}{n-1}
\]

Esto se puede sacar con la función \lstinline|var()| de \textsf{R}, por lo tanto, aplicando eso al vector \lstinline|x| se obtiene $0.9865382$.



\subsection{Comment on the results of (\ref{subsec:p1-c}) and (\ref{subsec:p1-d}). Were they surprising?}
\label{subsec:p1-e}

\subsubsection{Respuesta}

El resultado de \ref{subsec:p1-c} es la media de \lstinline|x| que es $-0.0160261$ y el de \ref{subsec:p1-d} es la varianza muestral de \lstinline|x| dando $0.9865382$. Estos valores muy sorprendentes no fueron... Se espera que al simular muchas veces una distribución normal, esta nos dé los valores de la media y la desviación estándar al cuadrado. Pero sí es interesante que dado este algoritmo para detenerse después de cruzar un $S / \sqrt{n}$ nos dé valores muy cercanos a una distribución normal con $\mu = 0$ y $\sigma = 1$.


\newpage

\section{Gaining confidence with confidence intervals}

We know that the $\mathcal{U}(-1, 1)$ r.v. has mean 0. Use a sample of size $1000$ to estimate the mean and give a $95\%$ confidence interval (CI). Does the CI contain 0? Repeat the above a large number of times ($\geq  100$). What percentage of time does the CI contain 0? Write your code so that it produces output similar to the following:

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.6\textwidth]{img/Punto2.png}
\end{figure}

\subsection{Respuesta}

Se sabe que para tener un intervalo de confianza de 95\%, el límite inferior y superior serán, respectivamente:

\[
\left( \bar{X} - 1.96 \frac{S}{\sqrt{n}}, \bar{X} + 1.96 \frac{S}{\sqrt{n}} \right)
\]

El siguiente código permite sacar el intervalo de confianza del 95\% y también el estimado de la media.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{n} \hlkwb{<-} \hlnum{1000}
\hldef{x} \hlkwb{<-} \hlkwd{runif}\hldef{(n,} \hlopt{-}\hlnum{1}\hldef{,} \hlnum{1}\hldef{)}
\hldef{xmean} \hlkwb{<-} \hlkwd{mean}\hldef{(x)}
\hldef{S} \hlkwb{<-} \hlkwd{sd}\hldef{(x)}
\hldef{L} \hlkwb{<-} \hldef{xmean} \hlopt{-} \hlnum{1.96} \hlopt{*} \hldef{S}\hlopt{/}\hlkwd{sqrt}\hldef{(n)}
\hldef{U} \hlkwb{<-} \hldef{xmean} \hlopt{+} \hlnum{1.96} \hlopt{*} \hldef{S}\hlopt{/}\hlkwd{sqrt}\hldef{(n)}
\hlkwd{cat}\hldef{(}\hlsng{"El estimado es"}\hldef{, xmean,} \hlsng{"\textbackslash{}n"}\hldef{)}
\end{alltt}
\begin{verbatim}
## El estimado es -0.008097984
\end{verbatim}
\begin{alltt}
\hlkwd{cat}\hldef{(}\hlsng{"95% está entre ("}\hldef{, L,} \hlsng{", "}\hldef{, U,} \hlsng{") \textbackslash{}n"}\hldef{,} \hlkwc{sep}\hldef{=}\hlsng{""}\hldef{)}
\end{alltt}
\begin{verbatim}
## 95% está entre (-0.04399638, 0.02780041)
\end{verbatim}
\end{kframe}
\end{knitrout}

Aquí se estimó la media de la distribución uniforme, dando un resultado de $-0.008098$, muy cercano a 0. El intervalo de confianza está entre $-0.0439964$ y $0.0278004$, en este caso sí contiene a 0.\footnote{Aquí hay que hacer una aclaración, los autores utilizaron \href{https://yihui.org/knitr/}{knitr}, una herramienta para la generación de reportes dinámicos en \textsf{R}, entonces cada vez que se compile este archivo \texttt{.Rnw} va a salir una salida diferente y puede ser que ya el intervalo no contenga 0.} Ahora, se va a realizar el proceso unas 200 veces para conocer el porcentaje de intervalos de confianza que contienen 0.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{trials} \hlkwb{<-} \hlnum{200}
\hldef{n} \hlkwb{<-} \hlnum{1000}
\hldef{true_mean} \hlkwb{<-} \hlnum{0}

\hldef{results} \hlkwb{<-} \hlkwd{data.frame}\hldef{(}
  \hlkwc{sample_mean} \hldef{=} \hlkwd{numeric}\hldef{(trials),}
  \hlkwc{lower_bound} \hldef{=} \hlkwd{numeric}\hldef{(trials),}
  \hlkwc{upper_bound} \hldef{=} \hlkwd{numeric}\hldef{(trials),}
  \hlkwc{contains_mean} \hldef{=} \hlkwd{integer}\hldef{(trials)}
\hldef{)}

\hlkwa{for} \hldef{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hldef{trials)\{}
  \hldef{x} \hlkwb{<-} \hlkwd{runif}\hldef{(n,} \hlopt{-}\hlnum{1}\hldef{,} \hlnum{1}\hldef{)}
  \hldef{xmean} \hlkwb{<-} \hlkwd{mean}\hldef{(x)}
  \hldef{S} \hlkwb{<-} \hlkwd{sd}\hldef{(x)}
  \hldef{L} \hlkwb{<-} \hldef{xmean} \hlopt{-} \hlnum{1.96} \hlopt{*} \hldef{S}\hlopt{/}\hlkwd{sqrt}\hldef{(n)}
  \hldef{U} \hlkwb{<-} \hldef{xmean} \hlopt{+} \hlnum{1.96} \hlopt{*} \hldef{S}\hlopt{/}\hlkwd{sqrt}\hldef{(n)}
  \hldef{contains} \hlkwb{<-} \hlkwd{as.integer}\hldef{(L} \hlopt{<=} \hldef{true_mean} \hlopt{&} \hldef{true_mean} \hlopt{<=} \hldef{U)}

  \hldef{results[i, ]} \hlkwb{<-} \hlkwd{c}\hldef{(xmean, L, U, contains)}
\hldef{\}}

\hlkwd{cat}\hldef{(}\hlsng{"Número de intentos:"}\hldef{, trials,} \hlsng{"\textbackslash{}n"}\hldef{)}
\end{alltt}
\begin{verbatim}
## Número de intentos: 200
\end{verbatim}
\begin{alltt}
\hlkwd{print}\hldef{(results,} \hlkwc{digits}\hldef{=} \hlnum{4}\hldef{)}
\end{alltt}
\begin{verbatim}
##     sample_mean lower_bound upper_bound contains_mean
## 1     0.0364579  -0.0001662   0.0730819             1
## 2     0.0142967  -0.0217361   0.0503295             1
## 3     0.0057865  -0.0298852   0.0414582             1
## 4     0.0226910  -0.0122302   0.0576121             1
## 5    -0.0338628  -0.0691641   0.0014384             1
## 6     0.0122799  -0.0237845   0.0483443             1
## 7    -0.0062031  -0.0419561   0.0295499             1
## 8    -0.0073949  -0.0425815   0.0277918             1
## 9     0.0204535  -0.0158474   0.0567543             1
## 10   -0.0114571  -0.0475604   0.0246461             1
## 11   -0.0021535  -0.0377371   0.0334301             1
## 12   -0.0148412  -0.0510246   0.0213422             1
## 13    0.0033426  -0.0320653   0.0387505             1
## 14   -0.0007512  -0.0367994   0.0352971             1
## 15    0.0276909  -0.0079468   0.0633286             1
## 16   -0.0294610  -0.0649093   0.0059872             1
## 17   -0.0152632  -0.0512033   0.0206769             1
## 18   -0.0129741  -0.0484331   0.0224849             1
## 19    0.0041249  -0.0317101   0.0399600             1
## 20   -0.0114717  -0.0473919   0.0244484             1
## 21   -0.0326625  -0.0686480   0.0033229             1
## 22   -0.0177694  -0.0532803   0.0177414             1
## 23    0.0192422  -0.0171083   0.0555927             1
## 24    0.0320541  -0.0032008   0.0673091             1
## 25   -0.0129260  -0.0483387   0.0224866             1
## 26   -0.0054461  -0.0418792   0.0309870             1
## 27   -0.0096732  -0.0462808   0.0269344             1
## 28   -0.0125340  -0.0483496   0.0232816             1
## 29    0.0136563  -0.0225146   0.0498272             1
## 30    0.0119750  -0.0236811   0.0476312             1
## 31    0.0401857   0.0053430   0.0750285             0
## 32    0.0261578  -0.0096140   0.0619296             1
## 33   -0.0263223  -0.0621255   0.0094808             1
## 34    0.0063396  -0.0292212   0.0419005             1
## 35    0.0134494  -0.0227631   0.0496619             1
## 36    0.0051077  -0.0309495   0.0411649             1
## 37   -0.0262132  -0.0613991   0.0089728             1
## 38   -0.0079707  -0.0443905   0.0284491             1
## 39   -0.0056004  -0.0412599   0.0300591             1
## 40   -0.0066387  -0.0428147   0.0295373             1
## 41    0.0159069  -0.0193457   0.0511594             1
## 42    0.0052011  -0.0296616   0.0400638             1
## 43    0.0028986  -0.0332364   0.0390336             1
## 44    0.0189909  -0.0163208   0.0543027             1
## 45    0.0324872  -0.0031214   0.0680958             1
## 46   -0.0008101  -0.0362994   0.0346791             1
## 47    0.0105334  -0.0252628   0.0463296             1
## 48   -0.0268184  -0.0632171   0.0095802             1
## 49   -0.0054599  -0.0414559   0.0305361             1
## 50   -0.0017993  -0.0374045   0.0338060             1
## 51    0.0053309  -0.0303694   0.0410312             1
## 52   -0.0248065  -0.0608856   0.0112725             1
## 53    0.0068572  -0.0289334   0.0426478             1
## 54    0.0318932  -0.0036519   0.0674383             1
## 55   -0.0170009  -0.0527776   0.0187758             1
## 56   -0.0245669  -0.0607573   0.0116236             1
## 57   -0.0019480  -0.0376434   0.0337473             1
## 58    0.0104449  -0.0248583   0.0457481             1
## 59    0.0031752  -0.0332313   0.0395817             1
## 60    0.0038305  -0.0312827   0.0389437             1
## 61    0.0332762  -0.0019199   0.0684723             1
## 62    0.0055933  -0.0303503   0.0415369             1
## 63   -0.0024760  -0.0385701   0.0336181             1
## 64    0.0093065  -0.0259851   0.0445981             1
## 65    0.0131571  -0.0225902   0.0489044             1
## 66   -0.0182566  -0.0540560   0.0175429             1
## 67    0.0068237  -0.0283891   0.0420366             1
## 68   -0.0019072  -0.0377299   0.0339155             1
## 69    0.0081725  -0.0273129   0.0436579             1
## 70    0.0493289   0.0139297   0.0847281             0
## 71   -0.0070391  -0.0431892   0.0291109             1
## 72    0.0104408  -0.0243644   0.0452460             1
## 73    0.0119704  -0.0242667   0.0482075             1
## 74   -0.0049135  -0.0413865   0.0315594             1
## 75    0.0187591  -0.0168405   0.0543586             1
## 76   -0.0230266  -0.0589437   0.0128904             1
## 77    0.0222047  -0.0138176   0.0582270             1
## 78   -0.0069848  -0.0438358   0.0298661             1
## 79    0.0072738  -0.0286041   0.0431517             1
## 80    0.0064621  -0.0288861   0.0418102             1
## 81   -0.0053746  -0.0413551   0.0306060             1
## 82   -0.0096593  -0.0449966   0.0256780             1
## 83   -0.0158240  -0.0511215   0.0194735             1
## 84   -0.0410248  -0.0762669  -0.0057827             0
## 85   -0.0068549  -0.0419685   0.0282588             1
## 86   -0.0119771  -0.0474935   0.0235392             1
## 87    0.0140059  -0.0215584   0.0495701             1
## 88    0.0103798  -0.0255022   0.0462617             1
## 89   -0.0030177  -0.0395312   0.0334958             1
## 90    0.0003937  -0.0355687   0.0363561             1
## 91    0.0365977   0.0006792   0.0725162             0
## 92    0.0109810  -0.0248052   0.0467672             1
## 93   -0.0022842  -0.0381128   0.0335445             1
## 94   -0.0097836  -0.0450991   0.0255318             1
## 95    0.0062782  -0.0287157   0.0412721             1
## 96   -0.0244353  -0.0605694   0.0116988             1
## 97   -0.0147384  -0.0500560   0.0205792             1
## 98    0.0267045  -0.0088925   0.0623016             1
## 99   -0.0130200  -0.0483145   0.0222744             1
## 100   0.0049142  -0.0317022   0.0415306             1
## 101   0.0341591  -0.0009603   0.0692784             1
## 102  -0.0215082  -0.0563448   0.0133284             1
## 103   0.0040691  -0.0319363   0.0400745             1
## 104   0.0129591  -0.0225116   0.0484297             1
## 105   0.0163186  -0.0192260   0.0518633             1
## 106   0.0036027  -0.0315500   0.0387554             1
## 107   0.0060579  -0.0300537   0.0421696             1
## 108  -0.0194922  -0.0549505   0.0159661             1
## 109  -0.0145109  -0.0509840   0.0219621             1
## 110  -0.0098297  -0.0448190   0.0251595             1
## 111  -0.0135374  -0.0488783   0.0218034             1
## 112   0.0038369  -0.0324650   0.0401388             1
## 113   0.0266269  -0.0089635   0.0622174             1
## 114   0.0061333  -0.0290714   0.0413379             1
## 115  -0.0012750  -0.0373154   0.0347654             1
## 116  -0.0277635  -0.0633186   0.0077917             1
## 117  -0.0112924  -0.0463553   0.0237706             1
## 118   0.0407241   0.0056337   0.0758146             0
## 119  -0.0095308  -0.0458293   0.0267676             1
## 120  -0.0266680  -0.0626360   0.0092999             1
## 121   0.0230322  -0.0126877   0.0587521             1
## 122  -0.0134492  -0.0494276   0.0225293             1
## 123   0.0067112  -0.0291135   0.0425359             1
## 124   0.0013030  -0.0341129   0.0367188             1
## 125  -0.0298601  -0.0662593   0.0065390             1
## 126  -0.0012520  -0.0372353   0.0347313             1
## 127  -0.0059511  -0.0416732   0.0297709             1
## 128   0.0194842  -0.0166917   0.0556601             1
## 129   0.0089197  -0.0266295   0.0444690             1
## 130   0.0159517  -0.0199107   0.0518140             1
## 131  -0.0037083  -0.0391089   0.0316922             1
## 132   0.0089446  -0.0273937   0.0452829             1
## 133  -0.0114426  -0.0471311   0.0242458             1
## 134   0.0157371  -0.0199722   0.0514463             1
## 135   0.0032817  -0.0325818   0.0391452             1
## 136  -0.0089766  -0.0449329   0.0269798             1
## 137   0.0054021  -0.0301521   0.0409562             1
## 138  -0.0041922  -0.0402894   0.0319050             1
## 139  -0.0315205  -0.0674431   0.0044020             1
## 140  -0.0084672  -0.0449088   0.0279744             1
## 141  -0.0047516  -0.0410577   0.0315544             1
## 142   0.0211775  -0.0145088   0.0568639             1
## 143   0.0128650  -0.0233070   0.0490370             1
## 144   0.0001258  -0.0354072   0.0356588             1
## 145  -0.0277180  -0.0637446   0.0083085             1
## 146   0.0587249   0.0224484   0.0950015             0
## 147  -0.0365955  -0.0716111  -0.0015799             0
## 148   0.0276163  -0.0075496   0.0627822             1
## 149   0.0146264  -0.0216582   0.0509111             1
## 150  -0.0053416  -0.0409059   0.0302228             1
## 151   0.0059978  -0.0300387   0.0420342             1
## 152   0.0079870  -0.0269330   0.0429070             1
## 153   0.0223367  -0.0131927   0.0578660             1
## 154  -0.0058717  -0.0408632   0.0291198             1
## 155   0.0040698  -0.0318950   0.0400346             1
## 156  -0.0150623  -0.0510245   0.0209000             1
## 157  -0.0092919  -0.0451588   0.0265751             1
## 158   0.0008165  -0.0354065   0.0370394             1
## 159  -0.0235628  -0.0593337   0.0122080             1
## 160  -0.0139975  -0.0498187   0.0218237             1
## 161  -0.0029924  -0.0389734   0.0329886             1
## 162   0.0153085  -0.0200493   0.0506664             1
## 163   0.0287916  -0.0066270   0.0642103             1
## 164   0.0004061  -0.0355947   0.0364069             1
## 165   0.0185714  -0.0164792   0.0536220             1
## 166  -0.0121163  -0.0479055   0.0236728             1
## 167  -0.0073958  -0.0437454   0.0289538             1
## 168   0.0158260  -0.0192227   0.0508746             1
## 169  -0.0552337  -0.0911706  -0.0192967             0
## 170   0.0318496  -0.0035990   0.0672983             1
## 171  -0.0354527  -0.0715656   0.0006601             1
## 172  -0.0145424  -0.0504470   0.0213623             1
## 173  -0.0240697  -0.0604758   0.0123364             1
## 174   0.0190497  -0.0167158   0.0548152             1
## 175   0.0275975  -0.0085928   0.0637878             1
## 176  -0.0219533  -0.0582392   0.0143326             1
## 177   0.0285657  -0.0075880   0.0647194             1
## 178   0.0116970  -0.0235877   0.0469817             1
## 179   0.0208385  -0.0153157   0.0569926             1
## 180  -0.0122812  -0.0487832   0.0242207             1
## 181  -0.0444422  -0.0789482  -0.0099363             0
## 182  -0.0063910  -0.0418607   0.0290788             1
## 183   0.0152519  -0.0205633   0.0510670             1
## 184   0.0138507  -0.0221019   0.0498032             1
## 185   0.0231955  -0.0120108   0.0584019             1
## 186  -0.0034487  -0.0393138   0.0324164             1
## 187  -0.0373172  -0.0725152  -0.0021192             0
## 188   0.0005718  -0.0353224   0.0364660             1
## 189   0.0222926  -0.0136692   0.0582544             1
## 190  -0.0157302  -0.0512085   0.0197482             1
## 191  -0.0189850  -0.0543294   0.0163593             1
## 192  -0.0052183  -0.0408722   0.0304357             1
## 193  -0.0012117  -0.0366004   0.0341769             1
## 194  -0.0019863  -0.0382430   0.0342705             1
## 195   0.0134991  -0.0225978   0.0495960             1
## 196   0.0018951  -0.0348576   0.0386479             1
## 197   0.0128518  -0.0221479   0.0478515             1
## 198  -0.0088060  -0.0446486   0.0270366             1
## 199  -0.0033254  -0.0395973   0.0329465             1
## 200  -0.0243368  -0.0602837   0.0116102             1
\end{verbatim}
\begin{alltt}
\hldef{porcentaje} \hlkwb{<-} \hlkwd{mean}\hldef{(results}\hlopt{$}\hldef{contains_mean)} \hlopt{*} \hlnum{100}

\hlkwd{cat}\hldef{(}\hlsng{"\textbackslash{}n"}\hldef{, porcentaje,} \hlsng{"% de los intervalos de"}\hldef{,}
\hlsng{"confianza contienen la media real\textbackslash{}n"}\hldef{)}
\end{alltt}
\begin{verbatim}
## 
##  95 % de los intervalos de confianza contienen la media real
\end{verbatim}
\end{kframe}
\end{knitrout}


En conclusión, el $95$ \% de los intervalos generados incluyen al 0.


\section{Standard deviation of a proportion}

Assume a manager is using the sample proportion $\hat{p}$ to estimate the proportion p of a new shipment of computer chips that are defective. He doesn’t know $p$ for this shipment, but in previous shipments it has been close to $0.01$, that is $1 \% $ of chips have been defective.

\subsection{If the manager wants the standard deviation of $\hat{p}$ to be about $0.02$, how large a sample should she take based on the assumption that the rate of defectives has not changed dramatically?}

En clase se vieron los estimadores de probabilidad, donde se quiere estimar

\[
  p = (P X \in A)
\]

Donde \(A\) es el subconjunto del espacio de estados de \(\Omega \) de \(X\). Es decir, para nuestro problema, este subconjunto de espacios en la muestra que tomó la administradora del cargamento de chips defectuosos. Se puede definir la variable indicadora \(Z\) como:

\[
  Z = 
  \begin{cases}
    1, & \quad X \in A \\
    0, & \quad X \notin A
  \end{cases}
\]

1 significa que sí está defectuoso y 0 que no lo está. Se puede escribir el estimador como:

\[
p = E[Z]
\]

En clase se realizó una demostración de como el valor esperado de \(Z\) se le puede asignar a \(p\). Se define la varianza de \(Z\) como:

\begin{align*}
\mathrm{Var}(Z) &= E[Z^{2}] - E[Z]^{2} \\
  &= (1^{2} \times P(X \in A) + 0^{2} \times P (X \notin A)) - (P(X \in A))^{²} \\
  &= p - p^{2}
\end{align*}

Aplicando factorización:

\[
\mathrm{Var}(Z) = p (1 - p)
\]

Estimar $p$ se puede realizar mediante el promedio muestral de $Z$, es decir, se puede estimar la proporción $\hat{p}$ con el promedio de los chips que son defectuosos:

\[
\hat{p} = \frac{1}{n} \sum_{i =1}^{n} Z_{i}
\]

Se puede calcular entonces, la varianza del estimador:

\[
\mathrm{Var}(\hat{p}) = \frac{1}{n} \mathrm{Var} \left(\sum_{i=1}^{n} Z_{i} \right)
\]

Por independencia de los valores del cargamento de chips $Z_{i}$ se puede meter la varianza de estos en la suma:

\begin{align*}
  \mathrm{Var}(\hat{p}) &= \frac{1}{n^{2}} \sum_{i=1}^{n} \mathrm{Var}(Z_{i}) \\
  &= \frac{1}{n^{2}} \sum_{i=1}^{n} p(1 - p) = \frac{1}{n} p (1 -p) 
\end{align*}

Por lo tanto, una aproximación es:

\[
\mathrm{Var}(\hat{p}) \approx \frac{1}{n} \hat{p} (1 - \hat{p}) 
\]

Teniendo en cuenta que la desviación estándar es el cuadrado de la varianza, se puede despejar:

\[
\sigma_{\hat{p}} \approx \sqrt{\frac{\hat{p} (1 - \hat{p})}{n}}
\]

El problema nos dice que la desviación estándar de $\hat{p}$ ($\sigma_{\hat{p}}$) debe ser sobre 0.02 y nos piden hallar cuántas muestras debe tomar la administradora, por lo tanto, en la parte izquierda de la ecuación reemplazamos por $0.02$, se despeja para $n$ y la proporción de defectuosos se toma como $0.01$ debido a que en el problema se nos dice que no ha cambiado tanto.

\begin{align*}
  \sigma_{\hat{p}} &\approx \sqrt{\frac{\hat{p} (1 - \hat{p})}{n}} \\
  0.02 &\approx \sqrt{\frac{0.1 (1 - 0.1)}{n}  } \\
  0.02 &\approx \sqrt{\frac{0.0099}{n}  } \\
  (0.02)^{2} &\approx \left(\cancel{\sqrt{\frac{0.0099}{n}  }} \right)^{\cancel{2}}\\
  0.0004 &\approx \frac{0.0099}{n} \\
  n &\approx \frac{0.0099}{0.0004} = 24.75
\end{align*}

Por lo tanto, la administradora debe tomar un muestra de por lo menos 25 chips para tener una desviación estándar de al menos $0.02$.

\subsection{Now suppose something went wrong with the production run and the actual proportion of defectives in the shipment is 0.3, that is 30 \% are defective. Now what would be the actual standard deviation of $\hat{p}$ for the sample size you choose in a)?}

Teniendo 25 chips y cambiando el valor de la proporción de defectuosos, se obtiene:

\begin{align*}
  \sigma_{\hat{p}} &\approx \sqrt{\frac{\hat{p}(1 - \hat{p}) }{n}} \\
                   &\approx   \sqrt{\frac{0.3(1 - 0.3) }{25}} \\
  &\approx 0.091
\end{align*}

Es decir, si la proporción de detección es del 30\%, la desviación estándar de $\hat{p}$ con una cantidad de chips de 25, será aproximadamente $0.091$,


\end{document}
