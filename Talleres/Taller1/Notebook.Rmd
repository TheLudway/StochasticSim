---
title: "Taller 1: Probabilidad, Variables aleatorias, Generadores aleatorios,
Simulación de Monte Carlo"
author: "Alvarado Ludwig | Vera Julián"
date: "2025-03-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 2: Congruential generators

Find all of the cycles of the following congruential ge-
nerator. For each cycle identify which seeds X0 lead to
that cycle:

$$
X_n = (9 X_{n-1} + 3) \mod 11
$$

Para eso, se va a crear la siguiente función `generator`.


```{r cars}
generator <- function(x_n1, n){
  for (i in 1:n){
    print(x_n1)
    x_n1 <- (9 * x_n1 + 3) %% 11
  }
}
```

La función se llama con un valor para la *seed* inicial y la cantidad $n$ de números pseudoaleatorios que se van a imprimir.

Para buscar todos los posibles ciclos, se va a intentar con diferentes valores del *seed* $X_{n-1}$, empezando por $X_{n-1} = 1$ y un $n = 8$ 

```{r}
generator(1, 8)
```

Podemos escribir las secuencias como $S = G(x)$ donde $G$ es la función `generator` y $x$ es el seed, y, $S$ es el conjunto de números generados por la función. Esto ayuda a simplificar la notación y ayuda a mejorar la lectura de las diferentes secuencias. Ya se tiene el de $G(1)$, ahora:

$G(2)$

```{r}
generator(2, 8)
```

$G(3)$

```{r}
generator(3, 8)
```

$G(4)$

```{r}
generator(4, 8)
```

$G(5)$

```{r}
generator(5, 8)
```


$G(6)$

```{r}
generator(6, 8)
```

$G(7)$

```{r}
generator(7, 8)
```


$G(8)$

```{r}
generator(8, 8)
```


$G(9)$

```{r}
generator(9, 8)
```


$G(10)$

```{r}
generator(10, 8)
```


$G(11)$

```{r}
generator(11, 8)
```


$G(12)$

```{r}
generator(12, 8)
```


$G(13)$

```{r}
generator(13, 8)
```

Los ciclos que se han obtenido son:

- $G(1): S = \{1, 1, 1, 1, 1, 1, 1, 1 \}$
- $G(2): S = \{2, 10, 5, 4, 6, 2, 10, 5\}$
- $G(3): S = \{3, 8, 9, 7, 0, 3, 8, 9\}$
- $G(4): S = \{4, 6, 2, 10, 5, 4, 6, 2\}$
- $G(5): S = \{5, 4, 6, 2, 10, 5, 4, 6, 2\}$
- $G(6): S = \{6, 2, 10, 5, 4, 6, 2, 10\}$
- $G(7): S = \{7, 0, 3, 8, 9, 7, 0, 3\}$
- $G(8): S = \{8, 9, 7, 0, 3, 8, 9, 7\}$
- $G(9): S = \{9, 7, 0, 3, 8, 9, 7 ,0\}$
- $G(10): S = \{10, 5, 4, 6, 2, 10, 5, 4\}$
- $G(11): S = \{11, 3, 8, 9, 7, 0, 3, 8\}$
- $G(12): S = \{12, 1, 1, 1, 1, 1, 1, 1\}$
- $G(13): S = \{13, 10, 5, 4, 6, 2,10, 5\}$


Las secuencias que se han identificado para los diferentes *seed* son:

- $X_{n-1} = 1:$ secuencia de solo unos.
- $X_{n-1} = 2:$ secuencia $\{10, 5, 4, 6, 2 \}$
- $X_{n-1} = 3:$ secuencia $\{3, 8, 9, 7, 0\}$

Estos *seeds* ($1, 2, 3$) son los que permiten generar secuencias diferentes.

Si nos damos cuenta, es normal que después del *seed* $3$ se empiecen a repetir los ciclos, esto se debe a que ya están todos los números menores a 11 en los conjuntos, por lo tanto, si cae otro *seed* se vuelve al ciclo.

## 3: Uniformity and independence of the uniform generator

```{r}
Nsim = 10^4 # Cantidad de números pseudoaleatorios a generar (10,000)
    
x=runif(Nsim) # Se almacenan los 10,000 números pseudoaleatorios en la variable x 
    
x1=x[-Nsim] # Se remueve el último elemento de x (último número pseudoaleatorio)
                  # y se almacena el restante en la variable x1
                  
x2=x[-1] # Se remueve el primer elemento de x (primer número pseudoaleatorio)
               # y se almacena el restante en la variable x2
               
par(mfrow=c(1,3)) # Se ajusta para que las tres gráficas queden una 
                        # al lado de la otra en una sola fila

hist(x) # Se genera un histograma a partir de x

plot(x1, x2) # Se genera un gráfico de dispersión entre las variables x1 y x2

acf(x) # Se genera un gráfico de dispersión para evaluar la autocorrelación 
             # entre los valores
```

## 4: Inverse method for a discrete r.v

### a

```{r}
x <- c(-1, 0, 1) # Valores de la variable aleatoria X
p <- c(0.2, 0.5, 0.3) # Probabilidad para cada valor de X

cdf <- cumsum(p) # Se calcula las probabilidades acumuladas con la funcion 'cumsum()'

f_x <- stepfun(x, c(0, cdf)) # Se inicializa la funcion de distribucion acumulada con la funcion 'stepfun()'

plot(f_x, xlin=c(-2, 2), main="CDF", xlab="x", ylab=expression(F[X](x)), do.points=TRUE, verticals=TRUE) # Se grafica la funcion de distribucion acumulada
```


### c

```{r}
n <- 1000 # Tamano de la muestra
u <- runif(n) # Se generan 'n' numeros aleatorios
x <- ifelse(u < 0.2, -1, ifelse(u < 0.7, 0, 1)) # Se establecen las condiciones de la funcion de distribucion acumulada, con respecto a los valores y sus probabilidades

prob <- table(x)/n # Se calculan las probabilidades para cada valor simulado de x

print(prob)
```

### d

```{r}
n <- 100 
u <- runif(n)
x <- ifelse(u < 0.2, -1, ifelse(u < 0.7, 0, 1)) 
x_barra <- mean(x) # Se calcula la media muestral
s <- sd(x) # Se calcula la Desviacion estandar muestral

# Resultados
cat("Media muestral =",x_barra, "\n")
cat("Desviacion estandar muestral (s) =",s, "\n")

E_X <- 0.1 # Valor del E[X]
APE1 <- abs(E_X - x_barra)/E_X * 100
cat("Error porcentual absoluto para E[X] =", APE1, "%\n")

SD_X <- 0.7
APE2 <- abs(SD_X - s)/SD_X * 100
cat("Error porcentual absoluto para sqrt(Var(X)) =", APE2, "%\n")
```



## 5: Inverse method for a continuos r.v.

### e. Write a program in R that draws 1000 samples of X. Plot a normalized histogram of the sample along with the PDF of X.

```{r}
U = runif(1000)
X = U ^ (1 / 3) + 1
hist(X)
```


## 6: Monte Carlo Integration

With respect to the following integrals: (i) Find their exact value analytically or with software (e.g., WolframAlpha), (ii) with Monte Carlo integration approximate the integrals and compare with the exact answer.

### $\int_{0}^{1} \exp{e^{x}} dx$

```{r}
a <- 0
b <- 1
N <- 100000
X <- runif(N, a, b)
g <- function(x) exp(exp(x))
gX <- g(X)
plot(X, gX)
(H <- mean(gX))
```

### $\int_{-2}^{2} e^{x + x^{2}} dx$

```{r}
a <- -2
b <- 2
N <- 100000
X <- runif(N, a, b)
g <- function(x) exp(x + x^2)
gX <- g(X)
plot(X, gX)
(H <- mean(gX))
```

### $\int_{0}^{\infty} x(1 + x^{2})^{-2} dx$

Se transformó la integral para que quede en un intervalo de 0 a 1 con la siguiente manera:

$$
\int_{0}^{1} \frac{\frac{ \frac{1}{y} - 1 }{ (1 + (\frac{1}{y} - 1)^{2} )^{2}}}{y^{2}} dy
$$

```{r}
a <- 0
b <- 1
N <- 100000 
X <- runif(N, a, b)
g <- function(y) ((1/y - 1)/(1 + (1/y - 1)^2)^2)/y^2
gX <- g(X)
plot(X, gX)
(H <- mean(gX))
```

### $\int_{0}^{1} \int_{0}^{1} e^{(x + y)^{2}} dydx$


```{r} 
ax <- 0 
bx <- 1
ay <- 0
by <- 2
N <- 1e5
runifX <- runif(N, ax, bx)
runifY <- runif(N, ay, by)
g <- function(x, y) exp((x + y)^2)
gXY <- g(runifX, runifY)
(H <- mean(gXY))
```


## Estimating expected values with Monte Carlo

```{r}
N <- function(){
  total <- 0
  count <- 0 
  while (total <= 1){
    total <- total + runif(1, 0, 1)
    count <- count + 1
  }
  return (count)
}

En <- function(N) { 
  samples <- replicate(N, N())
  return (mean(samples))
}

En_100 <- En(100)
En_1000 <- En(1000)
En_10000 <- En(100000)
En_100; En_1000; En_10000
```


## Estimating $\pi$


```{r}
n <- 10000 # Tamano de la muestra
X <- runif(n, -0.5, 0.5) # Se generan 'n' numeros aleatorios en el intervalo [-0.5,0.5] y se almacenan en la variable X
Y <- runif(n, -0.5, 0.5) # Se generan 'n' numeros aleatorios en el intervalo [-0.5,0.5] y se almacenan en la variable Y
Z <- ifelse(X^2+Y^2<=0.5^2,1,0) # Verificar si los puntos caen o no dentro del circulo
pi_estimado <- 4 * mean(Z) # Se estima pi
print(paste("Estimacion de pi con", n, "muestras:",pi_estimado))
```

