\documentclass[12pt]{article}\usepackage[]{graphicx}\usepackage[]{xcolor}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlsng}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hldef}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}
\usepackage[spanish,es-nodecimaldot]{babel}
\usepackage{xurl}
\usepackage{tcolorbox}
\usepackage{titlesec}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage{cancel}
\usepackage[hidelinks]{hyperref}
\usepackage[backend=biber]{biblatex}

\bibliography{referencias}



\titleclass{\subsubsubsection}{straight}[\subsection]

\newcounter{subsubsubsection}[subsubsection]
\renewcommand\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}
\renewcommand\theparagraph{\thesubsubsubsection.\arabic{paragraph}} % optional; useful if paragraphs are to be numbered

\titleformat{\subsubsubsection}
{\normalfont\normalsize\bfseries}{\thesubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsection}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{5}{\z@}%
  {3.25ex \@plus1ex \@minus.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\renewcommand\subparagraph{\@startsection{subparagraph}{6}{\parindent}%
  {3.25ex \@plus1ex \@minus .2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\def\toclevel@subsubsubsection{4}
\def\toclevel@paragraph{5}
% \def\toclevel@paragraph{6}
\def\toclevel@subparagraph{6}
\def\l@subsubsubsection{\@dottedtocline{4}{7em}{4em}}
\def\l@paragraph{\@dottedtocline{5}{10em}{5em}}
\def\l@subparagraph{\@dottedtocline{6}{14em}{6em}}
\makeatother

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

% Set up headers and footers
\pagestyle{fancy}
\fancyhf{}  % Clear previous settings

\fancyhead[L]{Julián - Ludwig}
\fancyhead[C]{Taller 2 - Sim Estocástica}
\fancyhead[R]{\today}

\fancyfoot[C]{\thepage}
\fancyfoot[C]{\footnotesize Este trabajo está bajo una licencia CC BY-SA 4.0. Más info: \url{https://creativecommons.org/licenses/by/4.0/}}

\renewcommand{\headrulewidth}{0.2pt}


% Define R Style for listings
\lstdefinestyle{RStyle}{
  language=R,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue}\bfseries,
  commentstyle=\color{green!40!black}\itshape,
  stringstyle=\color{red!70!black},
  numbers=left,
  numberstyle=\tiny\color{gray},
  stepnumber=1,
  numbersep=5pt,
  backgroundcolor=\color{gray!10},
  showstringspaces=false,
  breaklines=true,
  frame=single,
  rulecolor=\color{black},
  captionpos=b,
  morekeywords={generator}
}

% Set RStyle as default
\lstset{style=RStyle}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\section{Introducción}

El siguiente documento fue compilado usando \href{https://yihui.org/knitr/}{\textbf{knitr}} un paquete diseñado para la generación \textit{dinámica} de reportes para \textsf{R} y \textit{Python}. Esto se hace con el propósito de tener un documento consistente y replicable. Normalmente las entregas tienen un pantallazo del código y de la salida, sin embargo, esto además de verse muy \textit{feo} no tiene alguna manera sencilla de hacer la replicación de la simulación. Por eso mismo, en esta entrega se utiliza este paquete y facilitar manipulación, lectura del código, además de inmediatamente mostrar la salida de los códigos.

En el archivo comprimido \texttt{.7z} se encuentran varios archivos; \texttt{notas.tex}, \texttt{notas.Rnw}, \texttt{notas.pdf}, \texttt{referencias.bib}, \texttt{run.R}, \texttt{body\_fat.csv}, \texttt{loans\_income.csv}, \texttt{renv.lock} y unos directorios \texttt{img/} \texttt{renv/}. Aquí interesan dos archivos; \texttt{notas.Rnw} se encuentra todo el código fuente del documento (\LaTeX y \textsf{R}), en \texttt{run.R} se encuentra el \textit{script} para poder compilar el documento. Si se desea hacer uso del \textit{script} se necesitan unas librerías, paquetes y programas ya instalados en su máquina local, estos son; \LaTeX, se recomienda hacer la instalación local dependiendo de su sistema operativo; \textsf{R}, lenguaje de programación para estadística; \href{https://yihui.org/knitr/}{\textbf{knitr}}, para poder compilar el \texttt{.Rnw} y que genere un PDF. Con estas dependencias ya instaladas, tiene que ejecutar el archivo \texttt{run.R} (en sistemas UNIX como GNU/Linux, MacOSX, FreeBSD, etc. Se puede correr como cualquier \textit{script} de \textit{bash}, si cuenta con otro sistema operativo tiene que ejecutar el \textit{script} dentro de un entorno para correr código en \textsf{R}). Esto va a generar un PDF y de ahí puede ejecutar cuantas veces desee el \textit{script} y ver cómo cambian los valores del PDF dinámicamente. Si no desea hacer todo ese proceso de compilación del \texttt{.Rnw} puede ejecutar directamente el PDF que viene en el comprimido, siendo este la última salida de la compilación de los autores.

Por último, todo el presente trabajo fue hecho en un entorno virtual de \textsf{R} para evitar conflictos entre librerías, se trabajó con el paquete \lstinline|renv| para manejar el ambiente local junto con sus librerías. Puede revisar la documentación \href{https://rstudio.github.io/renv/articles/renv.html}{\textbf{aquí}} para tener más información de cómo manejar los ambientes virtuales y tener una mayor estabilidad en su sistema, así evita lo que le pasó a uno de los autores, que decidió instalar una librería en el ambiente global de \textit{Python} y dañó todo el sistema base.


\section{Stopping generating new simulation data}

Write a program to generate standard normal random variables until you have generated n of them, where $n \geq 100$ is such that $S/\sqrt{n} < 0.01$, where S is the sample standard deviation of the n data values. Note that this is the ``Method for Determining When to Stop Generating New Data''. Also, answer the following questions:



Debido a que se va a generar variables aleatorias \textbf{normales estándar} $X_{i}$, es decir, $X_{i} \sim \mathcal{N}(0, 1)$ y se debe parar de generar cuando $\frac{S}{\sqrt{n}} < 0.01$.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{x} \hlkwb{<-} \hlkwd{numeric}\hldef{()}
\hldef{s} \hlkwb{<-} \hlnum{1}
\hldef{n} \hlkwb{<-} \hlnum{0}

\hlkwa{while}\hldef{(n} \hlopt{<} \hlnum{100} \hlopt{||} \hldef{s} \hlopt{/} \hlkwd{sqrt}\hldef{(n)} \hlopt{>=} \hlnum{0.01}\hldef{) \{}
  \hldef{x} \hlkwb{<-} \hlkwd{c}\hldef{(x,} \hlkwd{rnorm}\hldef{(}\hlnum{1}\hldef{))}
  \hldef{n} \hlkwb{<-} \hlkwd{length}\hldef{(x)}
  \hldef{s} \hlkwb{<-} \hlkwd{sd}\hldef{(x)}
\hldef{\}}

\hlkwd{cat}\hldef{(}\hlsng{"Cantidad de Xi generados"}\hldef{, n,} \hlsng{"\textbackslash{}n"}\hldef{)}
\end{alltt}
\begin{verbatim}
## Cantidad de Xi generados 10198
\end{verbatim}
\begin{alltt}
\hlkwd{cat}\hldef{(}\hlsng{"Desviación estándar"}\hldef{,} \hlkwd{round}\hldef{(s,} \hlnum{5}\hldef{),} \hlsng{"\textbackslash{}n"}\hldef{)}
\end{alltt}
\begin{verbatim}
## Desviación estándar 1.00985
\end{verbatim}
\begin{alltt}
\hlkwd{cat}\hldef{(}\hlsng{"Error estándar S/sqrt(n)"}\hldef{,} \hlkwd{round}\hldef{(s}\hlopt{/}\hlkwd{sqrt}\hldef{(n),} \hlnum{5}\hldef{),} \hlsng{"\textbackslash{}n"}\hldef{)}
\end{alltt}
\begin{verbatim}
## Error estándar S/sqrt(n) 0.01
\end{verbatim}
\end{kframe}
\end{knitrout}


En el código se declara una variable $s$ inicializada en 1 para que luego sea nuevamente computada a la desviación estándar de $x$ que es un vector que va a almacenar todas las variables normales aleatorias generadas. Según el enunciado tenemos una condición de que al menos deben haber 100 variables aleatorias generadas ($n \geq 100$) y que el error estándar sea menor a 0.01 ($S / \sqrt{n} < 0.01$). En el ciclo \lstinline|while|, por lo tanto, tiene sentido que el ciclo continue si alguna de las afirmaciones anteriores son falsas, por eso queda la condición de esa manera. Se hace uso de la función \lstinline|rnorm(1)| para que genere una variable aleatoria normal con los valores por defecto (promedio 0 y desviación 1). 






\subsection{How many normals do you think will be generated? Give an analytic estimate.}
\label{subsec:p1-a}

\subsubsection{Respuesta}

Aunque ya se tengan los resultados de la simulación, se puede hacer un estimado analítico con la condición $S / \sqrt{n} < 0.01$ donde se puede despejar $n$ para saber cuántas variables se necesitan para parar el criterio.

Se tiene en primer lugar la inecuación:

\[
\frac{S}{\sqrt{n}} < 0.01
\]

Se eleva ambas partes con menos 1:

\begin{align*}
  \left(\frac{S}{\sqrt{n}}  \right)^{-1} &> 0.01^{-1} \\
  \frac{\sqrt{n}}{S}  &> 100
\end{align*}

Multiplicando ambas partes por $S$:

\begin{align*}
  \cancel{S} \times \frac{\sqrt{n}}{\cancel{S}}  &> 100 \times S \\
  \sqrt{n} &> 100 \times S 
\end{align*}

Ahora se cancela la raíz elevando ambas partes al cuadrado:

\begin{align*}
  (\cancel{\sqrt{n}})^{\cancel{2}} &> (100 \times S)^{2} 
\end{align*}

Quedando entonces:

\[
n > 10000\times S^{2}
\]

Para hacer el ejercicio se utilizó en \textsf{R} la función \texttt{rnorm(1, mean = 0, sd = 1)}, de esta manera genera únicamente 1 valor con media 0 y desviación 1, por lo tanto, podemos hacer $S = 1$ para estimar cuántos $n$ necesitamos para que se cumpla condición y deje de generar variables aleatorias, por lo tanto:

\begin{align*}
  n &> 10000 \times (1)^{2} \\
  n &> 10000 
\end{align*}

Este valor se acerca bastante al que se imprime en la simulación. 











\subsection{How many normals did you generate?}
\label{subsec:p1-b}

\subsubsection{Respuesta}

Se han generado \lstinline|n=| $10198$ normales.


\subsection{What is the sample mean of all the normals generated?}
\label{subsec:p1-c}




\subsubsection{Respuesta}

Utilizando el comando \lstinline|mean()| al vector \lstinline|x| se obtiene $0.0173852$. 

\subsection{What is the sample variance?}
\label{subsec:p1-d}


\subsubsection{Respuesta}

La varianza muestral se calcula como:

\[
S^{2} = \frac{\sum_{i=1}^{n} (X_{i} - \bar{X})^{2}}{n-1}
\]

Esto se puede sacar con la función \lstinline|var()| de \textsf{R}, por lo tanto, aplicando eso al vector \lstinline|x| se obtiene $1.0197956$.



\subsection{Comment on the results of (\ref{subsec:p1-c}) and (\ref{subsec:p1-d}). Were they surprising?}
\label{subsec:p1-e}

\subsubsection{Respuesta}

El resultado de \ref{subsec:p1-c} es la media de \lstinline|x| que es $0.0173852$ y el de \ref{subsec:p1-d} es la varianza muestral de \lstinline|x| dando $1.0197956$. Estos valores muy sorprendentes no fueron... Se espera que al simular muchas veces una distribución normal, esta nos dé los valores de la media y la desviación estándar al cuadrado. Pero sí es interesante que dado este algoritmo para detenerse después de cruzar un $S / \sqrt{n}$ nos dé valores muy cercanos a una distribución normal con $\mu = 0$ y $\sigma = 1$.



\section{Gaining confidence with confidence intervals}

We know that the $\mathcal{U}(-1, 1)$ r.v. has mean 0. Use a sample of size $1000$ to estimate the mean and give a $95\%$ confidence interval (CI). Does the CI contain 0? Repeat the above a large number of times ($\geq  100$). What percentage of time does the CI contain 0? Write your code so that it produces output similar to the following:


\begin{figure}[ht]
  \centering
  \includegraphics[width=0.6\textwidth]{img/Punto2.png}
\end{figure}

\subsection{Respuesta}

Se sabe que para tener un intervalo de confianza de 95\%, el límite inferior y superior serán, respectivamente:

\[
\left( \bar{X} - 1.96 \frac{S}{\sqrt{n}}, \bar{X} + 1.96 \frac{S}{\sqrt{n}} \right)
\]

El siguiente código permite sacar el intervalo de confianza del 95\% y también el estimado de la media.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{n} \hlkwb{<-} \hlnum{1000}
\hldef{x} \hlkwb{<-} \hlkwd{runif}\hldef{(n,} \hlopt{-}\hlnum{1}\hldef{,} \hlnum{1}\hldef{)}
\hldef{xmean} \hlkwb{<-} \hlkwd{mean}\hldef{(x)}
\hldef{S} \hlkwb{<-} \hlkwd{sd}\hldef{(x)}
\hldef{L} \hlkwb{<-} \hldef{xmean} \hlopt{-} \hlnum{1.96} \hlopt{*} \hldef{S}\hlopt{/}\hlkwd{sqrt}\hldef{(n)}
\hldef{U} \hlkwb{<-} \hldef{xmean} \hlopt{+} \hlnum{1.96} \hlopt{*} \hldef{S}\hlopt{/}\hlkwd{sqrt}\hldef{(n)}
\hlkwd{cat}\hldef{(}\hlsng{"El estimado es"}\hldef{, xmean,} \hlsng{"\textbackslash{}n"}\hldef{)}
\end{alltt}
\begin{verbatim}
## El estimado es -0.01663151
\end{verbatim}
\begin{alltt}
\hlkwd{cat}\hldef{(}\hlsng{"95% está entre ("}\hldef{, L,} \hlsng{", "}\hldef{, U,} \hlsng{") \textbackslash{}n"}\hldef{,} \hlkwc{sep}\hldef{=}\hlsng{""}\hldef{)}
\end{alltt}
\begin{verbatim}
## 95% está entre (-0.05192202, 0.01865899)
\end{verbatim}
\end{kframe}
\end{knitrout}

Aquí se estimó la media de la distribución uniforme, dando un resultado de $-0.0166315$, muy cercano a 0. El intervalo de confianza está entre $-0.051922$ y $0.018659$, en este caso sí contiene a 0.\footnote{Aquí hay que hacer una aclaración, los autores utilizaron \href{https://yihui.org/knitr/}{knitr}, una herramienta para la generación de reportes dinámicos en \textsf{R}, entonces cada vez que se compile este archivo \texttt{.Rnw} va a salir una salida diferente y puede ser que ya el intervalo no contenga 0.} Ahora, se va a realizar el proceso unas 200 veces para conocer el porcentaje de intervalos de confianza que contienen 0.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{trials} \hlkwb{<-} \hlnum{200}
\hldef{n} \hlkwb{<-} \hlnum{1000}
\hldef{true_mean} \hlkwb{<-} \hlnum{0}

\hldef{results} \hlkwb{<-} \hlkwd{data.frame}\hldef{(}
  \hlkwc{sample_mean} \hldef{=} \hlkwd{numeric}\hldef{(trials),}
  \hlkwc{lower_bound} \hldef{=} \hlkwd{numeric}\hldef{(trials),}
  \hlkwc{upper_bound} \hldef{=} \hlkwd{numeric}\hldef{(trials),}
  \hlkwc{contains_mean} \hldef{=} \hlkwd{integer}\hldef{(trials)}
\hldef{)}

\hlkwa{for} \hldef{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hldef{trials)\{}
  \hldef{x} \hlkwb{<-} \hlkwd{runif}\hldef{(n,} \hlopt{-}\hlnum{1}\hldef{,} \hlnum{1}\hldef{)}
  \hldef{xmean} \hlkwb{<-} \hlkwd{mean}\hldef{(x)}
  \hldef{S} \hlkwb{<-} \hlkwd{sd}\hldef{(x)}
  \hldef{L} \hlkwb{<-} \hldef{xmean} \hlopt{-} \hlnum{1.96} \hlopt{*} \hldef{S}\hlopt{/}\hlkwd{sqrt}\hldef{(n)}
  \hldef{U} \hlkwb{<-} \hldef{xmean} \hlopt{+} \hlnum{1.96} \hlopt{*} \hldef{S}\hlopt{/}\hlkwd{sqrt}\hldef{(n)}
  \hldef{contains} \hlkwb{<-} \hlkwd{as.integer}\hldef{(L} \hlopt{<=} \hldef{true_mean} \hlopt{&} \hldef{true_mean} \hlopt{<=} \hldef{U)}

  \hldef{results[i, ]} \hlkwb{<-} \hlkwd{c}\hldef{(xmean, L, U, contains)}
\hldef{\}}

\hlkwd{cat}\hldef{(}\hlsng{"Número de intentos:"}\hldef{, trials,} \hlsng{"\textbackslash{}n"}\hldef{)}
\end{alltt}
\begin{verbatim}
## Número de intentos: 200
\end{verbatim}
\begin{alltt}
\hlkwd{print}\hldef{(results,} \hlkwc{digits}\hldef{=} \hlnum{4}\hldef{)}
\end{alltt}
\begin{verbatim}
##     sample_mean lower_bound upper_bound contains_mean
## 1     9.114e-03  -0.0259926    0.044220             1
## 2     1.883e-02  -0.0165825    0.054250             1
## 3     1.106e-02  -0.0251099    0.047224             1
## 4    -5.354e-03  -0.0408235    0.030116             1
## 5     1.880e-03  -0.0324504    0.036210             1
## 6     2.786e-02  -0.0078839    0.063600             1
## 7     5.987e-03  -0.0302786    0.042253             1
## 8    -6.234e-03  -0.0418871    0.029419             1
## 9    -1.246e-02  -0.0492623    0.024349             1
## 10   -6.149e-03  -0.0410561    0.028758             1
## 11   -5.132e-03  -0.0410393    0.030775             1
## 12   -1.109e-02  -0.0465200    0.024337             1
## 13    1.308e-02  -0.0228377    0.049004             1
## 14   -2.340e-03  -0.0383425    0.033662             1
## 15    7.955e-03  -0.0287899    0.044700             1
## 16   -1.146e-02  -0.0466822    0.023762             1
## 17   -2.122e-02  -0.0575987    0.015158             1
## 18   -2.200e-02  -0.0568909    0.012886             1
## 19    1.686e-02  -0.0183366    0.052048             1
## 20    2.216e-03  -0.0337857    0.038218             1
## 21    3.978e-03  -0.0325484    0.040504             1
## 22    1.064e-02  -0.0240120    0.045291             1
## 23   -1.655e-02  -0.0517918    0.018701             1
## 24   -2.363e-02  -0.0592356    0.011980             1
## 25   -6.399e-03  -0.0419704    0.029172             1
## 26   -2.379e-02  -0.0590977    0.011512             1
## 27   -8.181e-03  -0.0437806    0.027418             1
## 28   -1.450e-02  -0.0499634    0.020964             1
## 29   -1.214e-02  -0.0477870    0.023497             1
## 30   -1.620e-02  -0.0518954    0.019491             1
## 31    1.943e-02  -0.0161756    0.055034             1
## 32    8.595e-03  -0.0273695    0.044560             1
## 33    2.043e-02  -0.0153104    0.056164             1
## 34   -3.439e-02  -0.0706630    0.001877             1
## 35    1.966e-02  -0.0163470    0.055657             1
## 36    1.222e-02  -0.0234325    0.047874             1
## 37   -1.430e-02  -0.0499019    0.021304             1
## 38   -2.051e-02  -0.0561805    0.015166             1
## 39    5.031e-03  -0.0307468    0.040809             1
## 40    6.933e-04  -0.0351831    0.036570             1
## 41    1.019e-02  -0.0251782    0.045548             1
## 42    4.521e-02   0.0090214    0.081405             0
## 43    4.542e-03  -0.0306436    0.039728             1
## 44    1.801e-06  -0.0357592    0.035763             1
## 45   -1.129e-02  -0.0466401    0.024066             1
## 46    8.932e-03  -0.0262723    0.044137             1
## 47   -1.937e-02  -0.0545625    0.015820             1
## 48   -4.169e-03  -0.0402089    0.031871             1
## 49   -2.265e-02  -0.0582527    0.012943             1
## 50    1.216e-02  -0.0232116    0.047528             1
## 51    3.689e-02   0.0007917    0.072989             0
## 52   -2.001e-03  -0.0381907    0.034189             1
## 53   -1.378e-02  -0.0496764    0.022112             1
## 54   -4.266e-03  -0.0407150    0.032182             1
## 55   -9.889e-03  -0.0452566    0.025478             1
## 56    1.095e-02  -0.0261696    0.048062             1
## 57    1.921e-02  -0.0171574    0.055573             1
## 58   -1.178e-02  -0.0474970    0.023939             1
## 59   -8.726e-03  -0.0450663    0.027615             1
## 60   -2.824e-02  -0.0641998    0.007728             1
## 61   -4.769e-03  -0.0399173    0.030380             1
## 62    3.001e-02  -0.0052267    0.065240             1
## 63    8.890e-03  -0.0265681    0.044349             1
## 64    3.453e-02  -0.0014190    0.070471             1
## 65    2.600e-02  -0.0094840    0.061479             1
## 66   -3.690e-03  -0.0404914    0.033111             1
## 67    2.815e-02  -0.0084581    0.064755             1
## 68    2.314e-03  -0.0333165    0.037945             1
## 69    7.242e-03  -0.0297992    0.044284             1
## 70   -2.589e-02  -0.0620649    0.010289             1
## 71    1.599e-02  -0.0191483    0.051128             1
## 72    7.368e-03  -0.0277467    0.042482             1
## 73   -4.265e-03  -0.0393907    0.030860             1
## 74    2.556e-02  -0.0106175    0.061728             1
## 75    2.561e-02  -0.0108899    0.062110             1
## 76   -3.112e-04  -0.0360654    0.035443             1
## 77    2.778e-03  -0.0329106    0.038466             1
## 78   -4.311e-03  -0.0406582    0.032037             1
## 79    3.943e-03  -0.0315251    0.039412             1
## 80   -1.886e-02  -0.0553230    0.017595             1
## 81   -3.333e-04  -0.0352785    0.034612             1
## 82    6.353e-03  -0.0289269    0.041632             1
## 83    1.781e-02  -0.0182680    0.053897             1
## 84    2.454e-02  -0.0103537    0.059443             1
## 85   -3.148e-02  -0.0679586    0.005002             1
## 86    1.273e-02  -0.0239809    0.049445             1
## 87   -1.474e-03  -0.0373964    0.034448             1
## 88   -7.918e-03  -0.0434727    0.027636             1
## 89   -2.758e-02  -0.0621813    0.007021             1
## 90    1.792e-02  -0.0180313    0.053880             1
## 91   -3.395e-02  -0.0699297    0.002037             1
## 92   -1.127e-02  -0.0458387    0.023306             1
## 93   -1.240e-02  -0.0479299    0.023123             1
## 94   -4.132e-02  -0.0765216   -0.006127             0
## 95    2.708e-02  -0.0084340    0.062600             1
## 96    1.249e-02  -0.0229147    0.047891             1
## 97   -2.190e-02  -0.0576468    0.013841             1
## 98   -6.273e-03  -0.0413547    0.028809             1
## 99    6.786e-03  -0.0288930    0.042464             1
## 100  -1.658e-02  -0.0524504    0.019283             1
## 101  -2.047e-03  -0.0378436    0.033750             1
## 102   4.558e-03  -0.0302380    0.039354             1
## 103  -1.707e-02  -0.0532893    0.019150             1
## 104   6.857e-03  -0.0294823    0.043196             1
## 105   3.683e-02   0.0011470    0.072508             0
## 106   1.173e-02  -0.0253368    0.048799             1
## 107   4.933e-02   0.0131008    0.085552             0
## 108   3.401e-02  -0.0022675    0.070293             1
## 109  -1.937e-03  -0.0386107    0.034737             1
## 110   3.432e-02  -0.0007225    0.069357             1
## 111  -7.145e-03  -0.0430597    0.028769             1
## 112  -1.238e-02  -0.0482504    0.023490             1
## 113   2.687e-02  -0.0094595    0.063201             1
## 114   8.631e-03  -0.0268261    0.044087             1
## 115   1.375e-02  -0.0221151    0.049624             1
## 116  -9.904e-03  -0.0456088    0.025801             1
## 117   8.005e-03  -0.0280895    0.044100             1
## 118   7.882e-03  -0.0275387    0.043303             1
## 119  -2.355e-02  -0.0591300    0.012037             1
## 120  -3.051e-02  -0.0667530    0.005724             1
## 121  -1.161e-02  -0.0473919    0.024182             1
## 122  -1.112e-03  -0.0358799    0.033656             1
## 123   3.149e-02  -0.0044495    0.067437             1
## 124   1.106e-02  -0.0246188    0.046730             1
## 125   4.471e-03  -0.0317559    0.040698             1
## 126  -7.970e-03  -0.0432378    0.027299             1
## 127   2.025e-02  -0.0151102    0.055606             1
## 128   1.498e-02  -0.0215990    0.051559             1
## 129   3.055e-02  -0.0044786    0.065574             1
## 130  -9.231e-03  -0.0447234    0.026260             1
## 131  -3.236e-02  -0.0681695    0.003456             1
## 132   2.110e-02  -0.0147306    0.056939             1
## 133  -1.650e-03  -0.0377649    0.034465             1
## 134  -1.203e-03  -0.0367873    0.034382             1
## 135   3.991e-02   0.0036337    0.076193             0
## 136   1.605e-02  -0.0205843    0.052679             1
## 137   1.738e-02  -0.0184283    0.053190             1
## 138   4.354e-02   0.0076194    0.079455             0
## 139   5.087e-03  -0.0306671    0.040841             1
## 140   3.743e-03  -0.0305178    0.038004             1
## 141  -4.356e-02  -0.0797014   -0.007415             0
## 142   2.252e-03  -0.0343834    0.038887             1
## 143   2.094e-02  -0.0148651    0.056739             1
## 144   1.626e-02  -0.0192407    0.051764             1
## 145   1.384e-02  -0.0214362    0.049108             1
## 146   1.370e-02  -0.0225243    0.049933             1
## 147  -1.086e-02  -0.0472441    0.025515             1
## 148   4.450e-03  -0.0312760    0.040176             1
## 149   6.852e-03  -0.0286596    0.042364             1
## 150  -2.081e-02  -0.0566383    0.015019             1
## 151  -3.608e-03  -0.0392265    0.032011             1
## 152  -5.167e-03  -0.0419837    0.031649             1
## 153   5.650e-02   0.0215266    0.091465             0
## 154  -8.887e-03  -0.0452865    0.027513             1
## 155   5.030e-03  -0.0310133    0.041072             1
## 156   2.137e-02  -0.0152626    0.057994             1
## 157   9.127e-03  -0.0267913    0.045046             1
## 158  -1.020e-02  -0.0456897    0.025298             1
## 159  -2.372e-03  -0.0380900    0.033347             1
## 160   2.810e-03  -0.0327780    0.038399             1
## 161  -1.833e-02  -0.0537669    0.017114             1
## 162  -2.113e-02  -0.0571027    0.014852             1
## 163  -2.870e-03  -0.0387719    0.033033             1
## 164  -8.018e-03  -0.0442808    0.028246             1
## 165  -2.240e-02  -0.0592792    0.014478             1
## 166  -2.698e-02  -0.0624579    0.008493             1
## 167   2.005e-02  -0.0159614    0.056053             1
## 168  -1.821e-02  -0.0546434    0.018215             1
## 169   3.898e-03  -0.0328464    0.040642             1
## 170  -2.703e-02  -0.0625422    0.008486             1
## 171   2.961e-02  -0.0055887    0.064807             1
## 172  -3.368e-04  -0.0365006    0.035827             1
## 173   1.089e-02  -0.0248871    0.046663             1
## 174   1.562e-02  -0.0192045    0.050435             1
## 175  -1.637e-02  -0.0524892    0.019757             1
## 176  -8.749e-03  -0.0442979    0.026800             1
## 177  -2.440e-02  -0.0607984    0.011996             1
## 178   1.583e-02  -0.0201671    0.051828             1
## 179  -4.655e-02  -0.0819730   -0.011118             0
## 180  -2.044e-02  -0.0570372    0.016164             1
## 181   3.853e-03  -0.0310463    0.038752             1
## 182  -2.604e-02  -0.0608398    0.008759             1
## 183   2.156e-02  -0.0143727    0.057485             1
## 184  -1.560e-03  -0.0366291    0.033510             1
## 185   8.378e-03  -0.0268459    0.043603             1
## 186  -1.737e-03  -0.0372613    0.033787             1
## 187   5.647e-04  -0.0357757    0.036905             1
## 188   2.505e-02  -0.0105823    0.060689             1
## 189   2.617e-03  -0.0339877    0.039222             1
## 190  -9.039e-03  -0.0447826    0.026704             1
## 191  -1.868e-03  -0.0382030    0.034467             1
## 192  -2.100e-02  -0.0579210    0.015919             1
## 193  -1.943e-02  -0.0556271    0.016762             1
## 194   3.817e-03  -0.0322500    0.039884             1
## 195   2.727e-02  -0.0092706    0.063820             1
## 196  -1.014e-02  -0.0455805    0.025307             1
## 197  -1.143e-03  -0.0361035    0.033817             1
## 198   1.072e-02  -0.0252266    0.046661             1
## 199  -1.388e-02  -0.0496213    0.021868             1
## 200   4.852e-03  -0.0313237    0.041028             1
\end{verbatim}
\begin{alltt}
\hldef{porcentaje} \hlkwb{<-} \hlkwd{mean}\hldef{(results}\hlopt{$}\hldef{contains_mean)} \hlopt{*} \hlnum{100}

\hlkwd{cat}\hldef{(}\hlsng{"\textbackslash{}n"}\hldef{, porcentaje,} \hlsng{"% de los intervalos de"}\hldef{,}
\hlsng{"confianza contienen la media real\textbackslash{}n"}\hldef{)}
\end{alltt}
\begin{verbatim}
## 
##  95 % de los intervalos de confianza contienen la media real
\end{verbatim}
\end{kframe}
\end{knitrout}


En conclusión, el $95$ \% de los intervalos generados incluyen al 0.


\section{Standard deviation of a proportion}

Assume a manager is using the sample proportion $\hat{p}$ to estimate the proportion p of a new shipment of computer chips that are defective. He doesn’t know $p$ for this shipment, but in previous shipments it has been close to $0.01$, that is $1 \% $ of chips have been defective.

\subsection{If the manager wants the standard deviation of $\hat{p}$ to be about $0.02$, how large a sample should she take based on the assumption that the rate of defectives has not changed dramatically?}

En clase se vieron los estimadores de probabilidad, donde se quiere estimar

\[
  p = (P X \in A)
\]

Donde \(A\) es el subconjunto del espacio de estados de \(\Omega \) de \(X\). Es decir, para nuestro problema, este subconjunto de espacios en la muestra que tomó la administradora del cargamento de chips defectuosos. Se puede definir la variable indicadora \(Z\) como:

\[
  Z = 
  \begin{cases}
    1, & \quad X \in A \\
    0, & \quad X \notin A
  \end{cases}
\]

1 significa que sí está defectuoso y 0 que no lo está. Se puede escribir el estimador como:

\[
p = E[Z]
\]

En clase se realizó una demostración de como el valor esperado de \(Z\) se le puede asignar a \(p\). Se define la varianza de \(Z\) como:

\begin{align*}
\mathrm{Var}(Z) &= E[Z^{2}] - E[Z]^{2} \\
  &= (1^{2} \times P(X \in A) + 0^{2} \times P (X \notin A)) - (P(X \in A))^{²} \\
  &= p - p^{2}
\end{align*}

Aplicando factorización:

\[
\mathrm{Var}(Z) = p (1 - p)
\]

Estimar $p$ se puede realizar mediante el promedio muestral de $Z$, es decir, se puede estimar la proporción $\hat{p}$ con el promedio de los chips que son defectuosos:

\[
\hat{p} = \frac{1}{n} \sum_{i =1}^{n} Z_{i}
\]

Se puede calcular entonces, la varianza del estimador:

\[
\mathrm{Var}(\hat{p}) = \frac{1}{n} \mathrm{Var} \left(\sum_{i=1}^{n} Z_{i} \right)
\]

Por independencia de los valores del cargamento de chips $Z_{i}$ se puede meter la varianza de estos en la suma:

\begin{align*}
  \mathrm{Var}(\hat{p}) &= \frac{1}{n^{2}} \sum_{i=1}^{n} \mathrm{Var}(Z_{i}) \\
  &= \frac{1}{n^{2}} \sum_{i=1}^{n} p(1 - p) = \frac{1}{n} p (1 -p) 
\end{align*}

Por lo tanto, una aproximación es:

\[
\mathrm{Var}(\hat{p}) \approx \frac{1}{n} \hat{p} (1 - \hat{p}) 
\]

Teniendo en cuenta que la desviación estándar es el cuadrado de la varianza, se puede despejar:

\[
\sigma_{\hat{p}} \approx \sqrt{\frac{\hat{p} (1 - \hat{p})}{n}}
\]

El problema nos dice que la desviación estándar de $\hat{p}$ ($\sigma_{\hat{p}}$) debe ser sobre 0.02 y nos piden hallar cuántas muestras debe tomar la administradora, por lo tanto, en la parte izquierda de la ecuación reemplazamos por $0.02$, se despeja para $n$ y la proporción de defectuosos se toma como $0.01$ debido a que en el problema se nos dice que no ha cambiado tanto.

\begin{align*}
  \sigma_{\hat{p}} &\approx \sqrt{\frac{\hat{p} (1 - \hat{p})}{n}} \\
  0.02 &\approx \sqrt{\frac{0.1 (1 - 0.1)}{n}  } \\
  0.02 &\approx \sqrt{\frac{0.0099}{n}  } \\
  (0.02)^{2} &\approx \left(\cancel{\sqrt{\frac{0.0099}{n}  }} \right)^{\cancel{2}}\\
  0.0004 &\approx \frac{0.0099}{n} \\
  n &\approx \frac{0.0099}{0.0004} = 24.75
\end{align*}

Por lo tanto, la administradora debe tomar un muestra de por lo menos 25 chips para tener una desviación estándar de al menos $0.02$.

\subsection{Now suppose something went wrong with the production run and the actual proportion of defectives in the shipment is 0.3, that is 30 \% are defective. Now what would be the actual standard deviation of $\hat{p}$ for the sample size you choose in a)?}

Teniendo 25 chips y cambiando el valor de la proporción de defectuosos, se obtiene:

\begin{align*}
  \sigma_{\hat{p}} &\approx \sqrt{\frac{\hat{p}(1 - \hat{p}) }{n}} \\
                   &\approx   \sqrt{\frac{0.3(1 - 0.3) }{25}} \\
  &\approx 0.091
\end{align*}

Es decir, si la proporción de detección es del 30\%, la desviación estándar de $\hat{p}$ con una cantidad de chips de 25, será aproximadamente $0.091$.

\section{Bets}

You pay $10.000$ pesos to participate in a bet game, which consists in tossing two coins together. If two heads fall, you earn $15.000$ pesos. If one head and one tail fall you earn $5.000$ pesos. In any other case you earn nothing. Let $X$ the random variable of your profit.

\subsection{Analytically find the probability mass function $p_{X}$, the mean $E[X]$, and variance $\mathrm{Var}(X)$ of $X$.}

Dado que $X$ es la variable aleatoria de la ganancia, podemos listar los posibles valores que puede tomar de acuerdo a los lanzamientos:

\begin{table}[ht]
  \centering
  \begin{tabular}[h]{|c|c|c|c|}
    \hline
    \textbf{Salida moneda} & \textbf{Ganancia} & \textbf{Ganancia} $X$ & \textbf{Probabilidad} \\ \hline
    HH & $15.000$ & $+5.000$ & 0.25 \\ \hline
    HT-TH & $5.000$ & $-5.000$ & 0.5 \\ \hline
    TT & $0$ & $-10.000$ & 0.25 \\ \hline 
  \end{tabular}
  \caption{Posibles salidas y ganancias al tirar dos monedas, (H) cara y (T) sello.}
  \label{tab:p3}
\end{table}

Del cuadro \ref{tab:p3} se toma que los posibles valores para las ganancias son:

\[
X \in \{-5000, -10000, 5000  \} 
\]

Teniendo en cuenta los valores que puede tomar $X$, la función probabilidad de masa debe retornar la probabilidad (valga la redundancia) de obtener alguno de los valores de $X$, en el cuadro \ref{tab:p3} se pueden ver dichas probabilidades, estas fueron calculadas de acuerdo a contar cuántas veces pueden salir los diferentes valores para la ganancia de $X$.

\[
p_{X} (x)  =
\begin{cases}
  0.25,& \quad x = 5000 \\
  0.5,&  \quad x = -5000 \\
  0.25,& \quad x = -10000 \\
  0,& \quad \text{En otro caso}
\end{cases}
\]

Debido a que estamos con un conjunto continuo para $X$, el valor esperado se multiplica la probabilidad por cada valor de este:

\begin{gather*}
  E[X] = \sum_{I=1}^{3} x \dot p_{X}(x) = 5000(0.25) + (-5000)(0.5) + (-10000)(0.25) \\
  E[X] = 1250 - 2500 - 2500 = -3750
\end{gather*}

Es decir, en promedio se pierde $3.750$ pesos por jugada.

Para calcular la varianza se puede utilizar la fórmula:

\[
\mathrm{Var}(X) = E[X^{2}] - (E[X])^{2}
\]

Se computa $E[X^{2}]$:

\begin{align*}
  E[X^{2}] &= 5000^{2}(0.25) + (-5000)^{2}(0.5) + (-10000)^{2}(0.25) \\
           &= 25000000 (0.25) + 25000000 (0.5) + 100000000 (0.25) \\
  &= 6250000 + 12500000 + 25000000 = 43750000
\end{align*}

Ahora se le resta el cuadrado de la media:

\[
\mathrm{Var}(X) = 43750000 - (-3750)^{2} = 43750000 - 14062500 = 29687500
\]






\subsection{Write a code that simulates the r.v. \textbf{X} using the command sample. Generate an \textit{iid} \lstinline|sample| $\{X_{i}\}$ of size $n = 10^{5}$.}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{outcomes} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlopt{-}\hlnum{10000}\hldef{,} \hlopt{-}\hlnum{5000}\hldef{,} \hlnum{5000}\hldef{)}
\hldef{probabilities} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlnum{0.25}\hldef{,} \hlnum{0.5}\hldef{,} \hlnum{0.25}\hldef{)}

\hldef{n} \hlkwb{<-} \hlnum{10}\hlopt{^}\hlnum{5}

\hldef{X} \hlkwb{<-} \hlkwd{sample}\hldef{(outcomes,} \hlkwc{size} \hldef{= n ,} \hlkwc{replace} \hldef{=} \hlnum{TRUE}\hldef{,} \hlkwc{prob} \hldef{= probabilities)}

\hlkwd{length}\hldef{(X)}
\end{alltt}
\begin{verbatim}
## [1] 100000
\end{verbatim}
\begin{alltt}
\hlkwd{summary}\hldef{(X)}
\end{alltt}
\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  -10000   -5000   -5000   -3769   -5000    5000
\end{verbatim}
\end{kframe}
\end{knitrout}

En este fragmento de código se realiza la creación del vector \lstinline|X| de tamaño $10^{5}$ creado con la función \lstinline|sample| que toma las salidas que se explicaron anteriormente, el tamaño de $10^{5}$, que se reemplace y la probabilidad.


\subsection{Modify your code to calculate: (i) the estimated mean profit $\bar{X}_{j}$ for each sample subsequence: $\{X_{1}, X_{2}, . . . , X_{j} \}$, $j = 2, 3, \dots, n$, (ii) the $95 \%$ CI’s of each estimated mean profit $\bar{X}_{j}$ .}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{mean_estimates} \hlkwb{<-} \hlkwd{numeric}\hldef{(n)}
\hldef{lower_CI} \hlkwb{<-} \hlkwd{numeric}\hldef{(n)}
\hldef{upper_CI} \hlkwb{<-} \hlkwd{numeric}\hldef{(n)}
\hldef{ie} \hlkwb{<-} \hlnum{1.96}

\hlkwa{for} \hldef{(j} \hlkwa{in} \hlnum{2}\hlopt{:}\hldef{n) \{}
  \hldef{x_sub} \hlkwb{<-} \hldef{X[}\hlnum{1}\hlopt{:}\hldef{j]}
  \hldef{mean_j} \hlkwb{<-} \hlkwd{mean}\hldef{(x_sub)}
  \hldef{sd_j} \hlkwb{<-} \hlkwd{sd}\hldef{(x_sub)}
  \hldef{se_j} \hlkwb{<-} \hldef{sd_j} \hlopt{/} \hlkwd{sqrt}\hldef{(j)}

  \hldef{mean_estimates[j]} \hlkwb{<-} \hldef{mean_j}
  \hldef{lower_CI[j]} \hlkwb{<-} \hldef{mean_j} \hlopt{-} \hldef{ie} \hlopt{*} \hldef{se_j}
  \hldef{upper_CI[j]} \hlkwb{<-} \hldef{mean_j} \hlopt{+} \hldef{ie} \hlopt{*} \hldef{se_j}
\hldef{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

En esta parte del código se crean tres vectores \lstinline|mean_estimates|, \lstinline|lower_CI|, \lstinline|upper_CI| de tamaño $10^{5}$ y también una variable \lstinline|ie|. El bucle en cada iteración calcula la media muestral de los valores $\bar{X}_{j}$, la desviación estándar \lstinline|sd_j| y el error estándar, estos son necesarios para luego calcular el intervalo de confianza junto con la media.


\subsection{Plot $\bar{X}_{j}$ and their $95 \%$ CI’s in terms of $j = 2, \dots , 10^{5}$. Add an horizontal line corresponding to the actual value $E[X]$.}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Your plotting code remains the same}
\hlkwd{plot}\hldef{(}\hlnum{2}\hlopt{:}\hldef{n, mean_estimates[}\hlnum{2}\hlopt{:}\hldef{n],} \hlkwc{type} \hldef{=} \hlsng{"l"}\hldef{,} \hlkwc{col} \hldef{=} \hlsng{"blue"}\hldef{,} \hlkwc{lwd} \hldef{=} \hlnum{1}\hldef{,}
     \hlkwc{xlab} \hldef{=} \hlsng{"j (tamaño de la submuestra)"}\hldef{,}
     \hlkwc{ylab} \hldef{=} \hlsng{"Ganancia esperada estimada"}\hldef{,}
     \hlkwc{main} \hldef{=} \hlsng{"Evolución de la media muestral y su IC del 95%"}\hldef{)}
\hlkwd{lines}\hldef{(}\hlnum{2}\hlopt{:}\hldef{n, lower_CI[}\hlnum{2}\hlopt{:}\hldef{n],} \hlkwc{col} \hldef{=} \hlsng{"red"}\hldef{,} \hlkwc{lty} \hldef{=} \hlnum{2}\hldef{)}
\hlkwd{lines}\hldef{(}\hlnum{2}\hlopt{:}\hldef{n, upper_CI[}\hlnum{2}\hlopt{:}\hldef{n],} \hlkwc{col} \hldef{=} \hlsng{"red"}\hldef{,} \hlkwc{lty} \hldef{=} \hlnum{2}\hldef{)}
\hlkwd{abline}\hldef{(}\hlkwc{h} \hldef{=} \hlopt{-}\hlnum{3750}\hldef{,} \hlkwc{col} \hldef{=} \hlsng{"darkgreen"}\hldef{,} \hlkwc{lty} \hldef{=} \hlnum{3}\hldef{,} \hlkwc{lwd} \hldef{=} \hlnum{2}\hldef{)}
\hlkwd{legend}\hldef{(}\hlsng{"topright"}\hldef{,} \hlkwc{legend} \hldef{=} \hlkwd{c}\hldef{(}\hlsng{"Media estimada"}\hldef{,} \hlsng{"IC 95%"}\hldef{,} \hlsng{"Valor real E[X]"}\hldef{),}
       \hlkwc{col} \hldef{=} \hlkwd{c}\hldef{(}\hlsng{"blue"}\hldef{,} \hlsng{"red"}\hldef{,} \hlsng{"darkgreen"}\hldef{),} \hlkwc{lty} \hldef{=} \hlkwd{c}\hldef{(}\hlnum{1}\hldef{,} \hlnum{2}\hldef{,} \hlnum{3}\hldef{),} \hlkwc{bty} \hldef{=} \hlsng{"n"}\hldef{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/grafico-pdf-1} 
\end{knitrout}

Se puede ver que a medida que se aumenta la submuestra $j$, la media estimada $\bar{X}$ se acerca más al valor esperado $E[X]$ y también, el intervalo de confianza se va acortando más.




\subsection{Repeat \textit{c)} and \textit{d)} to estimate the probabilities $p_{X} (x)$, their $95 \%$ CI’s, and their plots for each $j = 2, \dots , 10^{5}$, adding the actual values.}



\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Posibles valores de X}
\hldef{outcomes} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlopt{-}\hlnum{10000}\hldef{,} \hlopt{-}\hlnum{5000}\hldef{,} \hlnum{5000}\hldef{)}
\hldef{probs_true} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlnum{0.25}\hldef{,} \hlnum{0.5}\hldef{,} \hlnum{0.25}\hldef{)}

\hlcom{# Inicializar matrices para almacenar las estimaciones y CIs}
\hldef{p_estimates} \hlkwb{<-} \hlkwd{matrix}\hldef{(}\hlnum{0}\hldef{,} \hlkwc{nrow} \hldef{= n,} \hlkwc{ncol} \hldef{=} \hlnum{3}\hldef{)}
\hldef{p_lower} \hlkwb{<-} \hlkwd{matrix}\hldef{(}\hlnum{0}\hldef{,} \hlkwc{nrow} \hldef{= n,} \hlkwc{ncol} \hldef{=} \hlnum{3}\hldef{)}
\hldef{p_upper} \hlkwb{<-} \hlkwd{matrix}\hldef{(}\hlnum{0}\hldef{,} \hlkwc{nrow} \hldef{= n,} \hlkwc{ncol} \hldef{=} \hlnum{3}\hldef{)}

\hldef{z} \hlkwb{<-} \hlnum{1.96}  \hlcom{# Nivel de confianza del 95%}

\hlkwa{for} \hldef{(j} \hlkwa{in} \hlnum{2}\hlopt{:}\hldef{n) \{}
  \hldef{x_sub} \hlkwb{<-} \hldef{X[}\hlnum{1}\hlopt{:}\hldef{j]}
  \hlkwa{for} \hldef{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlnum{3}\hldef{) \{}
    \hldef{val} \hlkwb{<-} \hldef{outcomes[i]}
    \hldef{p_hat} \hlkwb{<-} \hlkwd{mean}\hldef{(x_sub} \hlopt{==} \hldef{val)}
    \hldef{se} \hlkwb{<-} \hlkwd{sqrt}\hldef{(p_hat} \hlopt{*} \hldef{(}\hlnum{1} \hlopt{-} \hldef{p_hat)} \hlopt{/} \hldef{j)}

    \hldef{p_estimates[j, i]} \hlkwb{<-} \hldef{p_hat}
    \hldef{p_lower[j, i]} \hlkwb{<-} \hlkwd{max}\hldef{(}\hlnum{0}\hldef{, p_hat} \hlopt{-} \hldef{z} \hlopt{*} \hldef{se)}
    \hldef{p_upper[j, i]} \hlkwb{<-} \hlkwd{min}\hldef{(}\hlnum{1}\hldef{, p_hat} \hlopt{+} \hldef{z} \hlopt{*} \hldef{se)}
  \hldef{\}}
\hldef{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\textbf{Gráfico de las probabilidades estimadas con sus ICs para cada posible valor de $X$:}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{colors} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlsng{"blue"}\hldef{,} \hlsng{"orange"}\hldef{,} \hlsng{"purple"}\hldef{)}
\hldef{labels} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlsng{"p_X(-10000)"}\hldef{,} \hlsng{"p_X(-5000)"}\hldef{,} \hlsng{"p_X(5000)"}\hldef{)}
\hldef{true_values} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlnum{0.25}\hldef{,} \hlnum{0.5}\hldef{,} \hlnum{0.25}\hldef{)}

\hlkwd{plot}\hldef{(}\hlnum{2}\hlopt{:}\hldef{n, p_estimates[}\hlnum{2}\hlopt{:}\hldef{n,}\hlnum{1}\hldef{],} \hlkwc{type} \hldef{=} \hlsng{"l"}\hldef{,} \hlkwc{col} \hldef{= colors[}\hlnum{1}\hldef{],} \hlkwc{ylim} \hldef{=} \hlkwd{c}\hldef{(}\hlnum{0}\hldef{,}\hlnum{1}\hldef{),}
     \hlkwc{xlab} \hldef{=} \hlsng{"j (tamaño de la submuestra)"}\hldef{,} \hlkwc{ylab} \hldef{=} \hlsng{"Probabilidad estimada"}\hldef{,}
     \hlkwc{main} \hldef{=} \hlsng{"Estimación de $p_X(x)$ con ICs del 95%"}\hldef{)}

\hlkwa{for} \hldef{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlnum{3}\hldef{) \{}
  \hlkwd{lines}\hldef{(}\hlnum{2}\hlopt{:}\hldef{n, p_estimates[}\hlnum{2}\hlopt{:}\hldef{n,i],} \hlkwc{col} \hldef{= colors[i],} \hlkwc{lwd} \hldef{=} \hlnum{1}\hldef{)}
  \hlkwd{lines}\hldef{(}\hlnum{2}\hlopt{:}\hldef{n, p_lower[}\hlnum{2}\hlopt{:}\hldef{n,i],} \hlkwc{col} \hldef{= colors[i],} \hlkwc{lty} \hldef{=} \hlnum{2}\hldef{)}
  \hlkwd{lines}\hldef{(}\hlnum{2}\hlopt{:}\hldef{n, p_upper[}\hlnum{2}\hlopt{:}\hldef{n,i],} \hlkwc{col} \hldef{= colors[i],} \hlkwc{lty} \hldef{=} \hlnum{2}\hldef{)}
  \hlkwd{abline}\hldef{(}\hlkwc{h} \hldef{= true_values[i],} \hlkwc{col} \hldef{= colors[i],} \hlkwc{lty} \hldef{=} \hlnum{3}\hldef{,} \hlkwc{lwd} \hldef{=} \hlnum{1.5}\hldef{)}
\hldef{\}}

\hlkwd{legend}\hldef{(}\hlsng{"topright"}\hldef{,} \hlkwc{legend} \hldef{= labels,} \hlkwc{col} \hldef{= colors,} \hlkwc{lty} \hldef{=} \hlnum{1}\hlopt{:}\hlnum{1}\hldef{,} \hlkwc{bty} \hldef{=} \hlsng{"n"}\hldef{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/plot-probabilities-1} 
\end{knitrout}

Se observa cómo las probabilidades estimadas convergen a los valores reales a medida que aumenta el tamaño de muestra $j$, y cómo los intervalos de confianza se vuelven más estrechos.


\section{Bootstrap}

This exercise is based on the article Introduction to Bootstrapping in Statistics with an Example and the dataset body fat.csv that contains the body fat percentages of 92 adolescent girls. Generate a program that gives:

\subsection{An histogram of the sample data.}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Leer el archivo}
\hldef{fat_data} \hlkwb{<-} \hlkwd{read.csv}\hldef{(}\hlsng{"body_fat.csv"} \hldef{)}

\hlcom{# Histograma}
\hlkwd{hist}\hldef{(fat_data[[}\hlkwd{colnames}\hldef{(fat_data)[}\hlnum{1}\hldef{]]],}
     \hlkwc{main} \hldef{=} \hlsng{"Histograma del porcentaje de grasa corporal"}\hldef{,}
     \hlkwc{xlab} \hldef{=} \hlsng{"Body Fat (%)"}\hldef{,}
     \hlkwc{col} \hldef{=} \hlsng{"skyblue"}\hldef{,}
     \hlkwc{border} \hldef{=} \hlsng{"white"}\hldef{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/histograma-fat-1} 
\end{knitrout}

Realizar el histograma en \textsf{R} es bastante sencillo, únicamente tener el archivo \texttt{.csv} en la misma ruta local que donde se está trabajando, utilizar la función \lstinline|read.csv()| para leer este archivo y luego con la función \lstinline|hist()| se colocan los datos de la primera columna y otras opciones para el estilo del gráfico.

Se muestra que la mayor frecuencia de grasa corporal se encuentra entre 20-30\%. 


\subsection{The 95 \% confidence interval of the mean of the data from the traditional method (i.e., via the Central Limit Theorem).}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Estadísticas necesarias}
\hldef{media} \hlkwb{<-} \hlkwd{mean}\hldef{(fat_data[[}\hlkwd{colnames}\hldef{(fat_data)[}\hlnum{1}\hldef{]]])}
\hldef{std} \hlkwb{<-} \hlkwd{sd}\hldef{(fat_data[[}\hlkwd{colnames}\hldef{(fat_data)[}\hlnum{1}\hldef{]]])}
\hldef{n} \hlkwb{<-} \hlkwd{length}\hldef{(fat_data[[}\hlkwd{colnames}\hldef{(fat_data)[}\hlnum{1}\hldef{]]])}

\hlcom{# Cálculo del error estándar}
\hldef{se} \hlkwb{<-} \hldef{std} \hlopt{/} \hlkwd{sqrt}\hldef{(n)}

\hlcom{# Intervalo de confianza del 95%}
\hldef{c} \hlkwb{<-} \hlnum{1.96}
\hldef{li} \hlkwb{<-} \hldef{media} \hlopt{-} \hldef{c}\hlopt{*}\hldef{se}
\hldef{ls} \hlkwb{<-} \hldef{media} \hlopt{+} \hldef{c}\hlopt{*}\hldef{se}

\hlcom{# Mostrar resultado}
\hlkwd{cat}\hldef{(}\hlkwd{sprintf}\hldef{(}\hlsng{"The 95%% confidence interval for the mean is: [%.2f, %.2f]"}\hldef{,}
                                                                \hldef{li, ls))}
\end{alltt}
\begin{verbatim}
## The 95% confidence interval for the mean is: [27.14, 29.99]
\end{verbatim}
\end{kframe}
\end{knitrout}

Como se puede apreciar en el programa, hay un 95\% de confianza para que la media esté en el intervalo $[27.1370094, 29.9934253]$. Las funciones de \textsf{R} ayudan mucho a hacer los cálculos del promedio, la desviación estándar y el valor de $n$ se sacaron con la ayuda de estas funciones. Los intervalos de confianza se sacaron como ya se viene haciendo, utilizando un $c = 1.96$.

\subsection{A number of 500 bootstrapped samples from the original dataset, with 92 observations each.}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{original_data} \hlkwb{<-} \hldef{fat_data[[}\hlkwd{colnames}\hldef{(fat_data)[}\hlnum{1}\hldef{]]]}
\hldef{n} \hlkwb{<-} \hlkwd{length}\hldef{(original_data)}

\hlcom{# Generar 500 muestras bootstrap}
\hldef{bootstrap_samples} \hlkwb{<-} \hlkwd{replicate}\hldef{(}\hlnum{500}\hldef{,} \hlkwd{sample}\hldef{(original_data,} \hlkwc{size} \hldef{= n,}
                    \hlkwc{replace} \hldef{=} \hlnum{TRUE}\hldef{),} \hlkwc{simplify} \hldef{=} \hlnum{FALSE}\hldef{)}
\end{alltt}
\end{kframe}
\end{knitrout}

Este código utiliza la función \lstinline|replicate()| para repetir la operación 500 veces, la función \lstinline|sample()| toma una muestra con reemplazo del tamaño de 92. Esto termina generando que \texttt{bootstrap\_samples} tenga 500 vectores, cada uno con 92 observaciones.

\subsection{An histogram of the means of each bootstrapped sample.}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Calcular la media de cada muestra bootstrap}
\hldef{bootstrap_means} \hlkwb{<-} \hlkwd{sapply}\hldef{(bootstrap_samples, mean)}

\hlcom{# Histograma de las medias}
\hlkwd{hist}\hldef{(bootstrap_means,}
     \hlkwc{main} \hldef{=} \hlsng{"Histograma de medias de muestras bootstrap"}\hldef{,}
     \hlkwc{xlab} \hldef{=} \hlsng{"Media del % de grasa corporal"}\hldef{,}
     \hlkwc{col} \hldef{=} \hlsng{"lightgreen"}\hldef{,}
     \hlkwc{border} \hldef{=} \hlsng{"white"}\hldef{,}
     \hlkwc{probability} \hldef{=} \hlnum{TRUE}\hldef{)}  \hlcom{# Importante: escala el eje y para densidades}

\hlcom{# Parámetros de la normal}
\hldef{mean_boot} \hlkwb{<-} \hlkwd{mean}\hldef{(bootstrap_means)}
\hldef{sd_boot} \hlkwb{<-} \hlkwd{sd}\hldef{(bootstrap_means)}

\hlcom{# Añadir curva de distribución normal}
\hlkwd{curve}\hldef{(}\hlkwd{dnorm}\hldef{(x,} \hlkwc{mean} \hldef{= mean_boot,} \hlkwc{sd} \hldef{= sd_boot),}
      \hlkwc{col} \hldef{=} \hlsng{"blue"}\hldef{,} \hlkwc{lwd} \hldef{=} \hlnum{2}\hldef{,} \hlkwc{add} \hldef{=} \hlnum{TRUE}\hldef{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/bootstrap-histogram-1} 
\end{knitrout}

Con la función \lstinline|sapply()| le aplica a los elementos en \texttt{bootstrap\_samples} la función \lstinline|mean()|. Después se crea el histograma y se dibuja una curva de tipo campana para una ditribución normal, reflejando la similitud de los promedios de los \textit{bootstraps}.

\subsection{A 95 \% bootstrapped confidence interval of the mean.}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Calcular intervalo de confianza bootstrap del 95%}
\hldef{bootstrap_ci} \hlkwb{<-} \hlkwd{quantile}\hldef{(bootstrap_means,} \hlkwc{probs} \hldef{=} \hlkwd{c}\hldef{(}\hlnum{0.025}\hldef{,} \hlnum{0.975}\hldef{))}


\hldef{bootstrap_ci}
\end{alltt}
\begin{verbatim}
##     2.5%    97.5% 
## 27.14875 30.03261
\end{verbatim}
\end{kframe}
\end{knitrout}

 
Se utiliza la función \lstinline|quantile()| para obtener los intervalos exactos, para posteriormente poder hacer la comparación de ambos resultados.

Entonces, el 95\% del intervalo de confianza para la media es:

\[
\left[ 27.15,\; 30.03 \right]
\]


\subsection{A comparison of both confidence intervals}


Con el método tradicional del teórema central del límite:

\[
  \left[ 27.14,\; 29.99 \right]
\]

Con el método \textit{bootstrap}

\[
  \left[ 27.15,\; 30.03 \right]
\]

\section{Reliability of a system}

Suppose a 3-out-of-4 system where each component is functioning with probabilities $p = \{pi\}$:


\subsection{Write the structure function of the system $\phi(x)$.}

La estructura funciona si al menos 3 de los 4 componentes están estructurados. Dado que hay dos estados; funciona ($\phi = 1$) o lo contrario ($\phi = 0$). Se puede tener un estado de los componentes $x = (x_{1}, x_{2}, x_{3}, x_{4})$, donde cada $x_{i} \in \{0, 1 \}$ representa si el componente $i$ está funcionando.

La estructura entonces es:

\[
\phi (x_{1}, x_{2}, x_{3}, x_{4}) =
\begin{cases}
  1 & \quad \text{si } x_{1} + x_{2} + x_{3} + x_{4} \geq 3 \\
  0 & \quad \text{si } x_{1} + x_{2} + x_{3} + x_{4} < 3
\end{cases}
\]

\subsection{Deduce analytically the reliability function $R(\mathbf{p})$. Evaluate it when $\{p_{i} \} = \{0.9, 0.5, 0.2, 0.1\} $}
\label{subsec:p6-b}

Se tomó gran parte de la información del libro \textit{Introduction to Probability Models} de Sheldon Ross \cite{ross2014introduction}.


Suponiendo que $X_{i}$, el estado del $i$-ésimo componente, es una variable aleatoria tal que:

\[
P\{X_{i} = 1 \} = p_{i} = 1 - P\{X_{i} = 0 \}
\]

El valor $p_{i}$ es la probabilidad de que el $i$-ésimo componente está funcionando, esto se llama la confiabilidad del $i$-ésimo componente. Si definimos $r$ como:

\[
r = P\{\phi (X) = 1 \}, \quad \text{donde } X = (X_{1}, \dots, X_{n})
\]

$r$ es llamada la confiabilidad del sistema. Cuando los componentes, es decir, las variables aleatorias $X_{i}, i = 1, \dots, n$, son independientes, se expresa $r$ como una función de componentes de confiabilidad. Es decir:

\[
r = r (\mathbf{p}), \quad \text{donde } \mathbf{p} = (p_{1}, \dots, p_{n})
\]

Esta función $r(\mathbf{p})$ es llamada la función de confiabilidad, que es la que se busca encontrar paes este sistema 3-out-of-4.

Dado que para este sistema se necesita que por lo menos 3 de los 4 componentes sirvan, uno puede pasar a la función $\phi$ unos parámetros de $(1, 1, 1, 0)$, simbolizando que los componentes $x_{1}, x_{2}$ y $ x_{3}$ están funcionando. La función de confiabilidad está dada entonces por todas las posibles combinaciones de los elementos que sumadas den mayor o igual a 3, es decir:

\[
r(\mathbf{p}) = P \left\{ \sum_{i=1}^{n} X_{i} \geq 3  \right\}
\]

Esto se puede expandir como:

\begin{multline*}
  r(\mathbf{p}) = P\{X = (1, 1, 1, 1) \} + P\{X = (1, 1, 1, 0) \} + P\{X = (1, 1, 0, 1) \} + P\{X = (1, 0, 1, 1) \} \\+ P\{X = (0, 1, 1, 1) \}
\end{multline*}

Teniendo que $p_{i}$ simboliza la probabilidad de que el $i$-ésimo componente está funcionando y 1 - $p_{i}$ es que no está funcionando el componente, lo anterior se puede escribir como:

\begin{multline*}
r(\mathbf{p}) = p_{1}p_{2}p_{3}p_{4} + p_{1}p_{2}p_{3}(1-p_{4}) + p_{1}p_{2}(1-p_{3})p_{4} + p_{1}(1-p_{2})p_{3}p_{4} + (1-p_{1})p_{2}p_{3}p_{4}  
\end{multline*}
 

Los casos para los cuales el sistema cuenta con un componente no funcionando, es decir, $1 - p_{i}$, se pueden agrupar en uno mismo, quedando:

\[
\begin{aligned}
  r(\mathbf{p}) = p_{1}p_{2}p_{3}p_{4} + p_{1}p_{2}p_{3} + p_{1}p_{2}p_{4}\\
  + p_{1}p_{3}p_{4} + p_{2}p_{3}p_{4} - 4p_{1}p_{2}p_{3}p_{4}  
\end{aligned}
\]

Sustrayendo con el término positivo $p_{1}p_{2}p_{3}p_{4}$:
\begin{tcolorbox}
\[
  \begin{aligned}
    r(\mathbf{p}) = p_{1}p_{2}p_{3} + p_{1}p_{2}p_{4} + p_{1}p_{3}p_{4}+ p_{2}p_{3}p_{4} - 3p_{1}p_{2}p_{3}p_{4}
  \end{aligned}
\]
\end{tcolorbox}

Ahora, podemos evaluar cuando $\mathbf{p} = \{0.9, 0.5, 0.2, 0.1 \}$:

\[
  \begin{aligned}
    r(\mathbf{p}) = 0.9 \times 0.5 \times 0.2 + 0.9 \times 0.5\times 0.1 + 0.9 \times 0.2 \times 0.1 \\ + 0.5\times 0.2 \times 0.1 - 3( 0.9\times 0.5 \times  0.2\times  0.1 )
  \end{aligned}
\]

Esto se puede colocar en una calculadora y va a dar el resultado de $\mathbf{0.136}$, se puede construir una pequeña función en \textsf{R} para ahorrar calculos en el caso de que se den más conjuntos para $\mathbf{p}$:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{reli_fun} \hlkwb{<-} \hlkwa{function}\hldef{(}\hlkwc{p1}\hldef{,} \hlkwc{p2}\hldef{,} \hlkwc{p3}\hldef{,} \hlkwc{p4}\hldef{)\{}
  \hlkwd{return} \hldef{(p1}\hlopt{*}\hldef{p2}\hlopt{*}\hldef{p3} \hlopt{+} \hldef{p1}\hlopt{*}\hldef{p2}\hlopt{*}\hldef{p4} \hlopt{+} \hldef{p1}\hlopt{*}\hldef{p3}\hlopt{*}\hldef{p4} \hlopt{+} \hldef{p2}\hlopt{*}\hldef{p3}\hlopt{*}\hldef{p4} \hlopt{-} \hlnum{3} \hlopt{*} \hldef{(p1} \hlopt{*} \hldef{p2} \hlopt{*} \hldef{p3} \hlopt{*} \hldef{p4))}
\hldef{\}}

\hlkwd{reli_fun}\hldef{(}\hlnum{0.9}\hldef{,} \hlnum{0.5}\hldef{,} \hlnum{0.2}\hldef{,} \hlnum{0.1}\hldef{)}
\end{alltt}
\begin{verbatim}
## [1] 0.136
\end{verbatim}
\end{kframe}
\end{knitrout}

\subsection{Estimate via simulation, for each $n = 10^{2} , 10^{3} , 10^{4} , 10^{5}$ realizations, the reliability of the system $R(p)$. Take $\{pi \} = \{0.9, 0.5, 0.2, 0.1\}$.}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Given probabilities}
\hldef{p} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlnum{0.9}\hldef{,} \hlnum{0.5}\hldef{,} \hlnum{0.2}\hldef{,} \hlnum{0.1}\hldef{)}

\hlcom{# Function to calculate system reliability for one trial}
\hldef{calculate_reliability} \hlkwb{<-} \hlkwa{function}\hldef{(}\hlkwc{p}\hldef{) \{}
  \hlcom{# Simulate the components as working (1) or failing (0) based on probabilities}
  \hldef{x} \hlkwb{<-} \hlkwd{rbinom}\hldef{(}\hlnum{4}\hldef{,} \hlnum{1}\hldef{, p)}

  \hlcom{# Apply the reliability function r(p) as given}
  \hldef{r} \hlkwb{<-} \hlkwd{sum}\hldef{(x[}\hlnum{1}\hldef{]}\hlopt{*}\hldef{x[}\hlnum{2}\hldef{]}\hlopt{*}\hldef{x[}\hlnum{3}\hldef{])} \hlopt{+} \hlkwd{sum}\hldef{(x[}\hlnum{1}\hldef{]}\hlopt{*}\hldef{x[}\hlnum{2}\hldef{]}\hlopt{*}\hldef{x[}\hlnum{4}\hldef{])} \hlopt{+} \hlkwd{sum}\hldef{(x[}\hlnum{1}\hldef{]}\hlopt{*}\hldef{x[}\hlnum{3}\hldef{]}\hlopt{*}\hldef{x[}\hlnum{4}\hldef{])} \hlopt{+}
              \hlkwd{sum}\hldef{(x[}\hlnum{2}\hldef{]}\hlopt{*}\hldef{x[}\hlnum{3}\hldef{]}\hlopt{*}\hldef{x[}\hlnum{4}\hldef{])} \hlopt{-} \hlnum{3} \hlopt{*} \hlkwd{prod}\hldef{(x)}

  \hlkwd{return}\hldef{(r)}
\hldef{\}}

\hlcom{# Function to run simulation for different number of realizations n}
\hldef{simulate_system_reliability} \hlkwb{<-} \hlkwa{function}\hldef{(}\hlkwc{n}\hldef{,} \hlkwc{p}\hldef{) \{}
  \hldef{reliabilities} \hlkwb{<-} \hlkwd{numeric}\hldef{(n)}

  \hlkwa{for} \hldef{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hldef{n) \{}
    \hldef{reliabilities[i]} \hlkwb{<-} \hlkwd{calculate_reliability}\hldef{(p)}
  \hldef{\}}
  \hlkwd{return}\hldef{(}\hlkwd{mean}\hldef{(reliabilities))}
\hldef{\}}

\hlcom{# Run simulation for each n: 10^2, 10^3, 10^4, 10^5 realizations}
\hldef{results} \hlkwb{<-} \hlkwd{sapply}\hldef{(}\hlkwd{c}\hldef{(}\hlnum{10}\hlopt{^}\hlnum{2}\hldef{,} \hlnum{10}\hlopt{^}\hlnum{3}\hldef{,} \hlnum{10}\hlopt{^}\hlnum{4}\hldef{,} \hlnum{10}\hlopt{^}\hlnum{5}\hldef{),}
            \hlkwa{function}\hldef{(}\hlkwc{n}\hldef{)} \hlkwd{simulate_system_reliability}\hldef{(n, p))}

\hlcom{# View results}
\hlkwd{names}\hldef{(results)} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlsng{"n=10^2"}\hldef{,} \hlsng{"n=10^3"}\hldef{,} \hlsng{"n=10^4"}\hldef{,} \hlsng{"n=10^5"}\hldef{)}
\hlkwd{print}\hldef{(results)}
\end{alltt}
\begin{verbatim}
##  n=10^2  n=10^3  n=10^4  n=10^5 
## 0.12000 0.12600 0.14050 0.13702
\end{verbatim}
\end{kframe}
\end{knitrout}


En primer lugar se tiene un vector \lstinline|x| que simula cada componente del sistema retornando 1 o 0 con una probabilidad que es el conjunto para $p_{i}$ que se define en el enunciado del problema. Después se pasa a la función de confiabilidad. Seguido, se pasa a la función \lstinline|simulate_system_reliability()| donde se simula la confiabilidad $n$ veces y se guarda en un vector \lstinline|reliabilities|. Por último, se corre la simulación para diferentes valores de $n$, guardando todo en \lstinline|results|. Los resultados se presentan en el cuadro \ref{tab:reliability} y se ve que a medida que se hacen más simulaciones, la probabilidad de que el sistema esté funcionando se va acercando al valor obtenido analíticamente de 0.136.

\begin{table}[ht]
  \centering
  \begin{tabular}{|c|c|}
    \hline
    $n$& Confiabilidad de que el sistema está funcionando. \\ \hline
    $10^{2}$ & $0.12$ \\ \hline
    $10^{3}$ & $0.126$ \\ \hline
    $10^{4}$ & $0.1405$\\ \hline
    $10^{5}$ & $0.13702$\\ \hline
  \end{tabular}
  \caption{Resultados de la función confiabilidad para diferentes valores de $n$. }
  \label{tab:reliability}
\end{table}

\subsection{Find the standard deviation of the reliability estimation for each $n$.}

Se hace una modificación a la función \lstinline|simulate_system_reliability()| para que también entregue la desviación estándar de cada estimación de la confiabilidad.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{simulate_system_reliability} \hlkwb{<-} \hlkwa{function}\hldef{(}\hlkwc{n}\hldef{,} \hlkwc{p}\hldef{) \{}
 \hldef{reliabilities} \hlkwb{<-} \hlkwd{numeric}\hldef{(n)}

 \hlkwa{for} \hldef{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hldef{n) \{}
   \hldef{reliabilities[i]} \hlkwb{<-} \hlkwd{calculate_reliability}\hldef{(p)}
 \hldef{\}}

 \hldef{sd_val} \hlkwb{<-} \hlkwd{sd}\hldef{(reliabilities)}

 \hlkwd{return}\hldef{(}\hlkwd{c}\hldef{(}\hlkwc{SD} \hldef{= sd_val))}
\hldef{\}}
\end{alltt}
\end{kframe}
\end{knitrout}


Se deja tal cual estaba la función, pero ahora retorna la desviación estándar de esa estimación para ese $n$ en específico. Por lo tanto, ahora queda volver a correr la simulación para los diferentes $n$.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{results} \hlkwb{<-} \hlkwd{sapply}\hldef{(}\hlkwd{c}\hldef{(}\hlnum{10}\hlopt{^}\hlnum{2}\hldef{,} \hlnum{10}\hlopt{^}\hlnum{3}\hldef{,} \hlnum{10}\hlopt{^}\hlnum{4}\hldef{,} \hlnum{10}\hlopt{^}\hlnum{5}\hldef{),} \hlkwa{function}\hldef{(}\hlkwc{n}\hldef{)} \hlkwd{simulate_system_reliability}\hldef{(n, p))}
\hlkwd{names}\hldef{(results)} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlsng{"n=10^2"}\hldef{,} \hlsng{"n=10^3"}\hldef{,} \hlsng{"n=10^4"}\hldef{,} \hlsng{"n=10^5"}\hldef{)}

\hlcom{# Print results}
\hlkwd{print}\hldef{(results)}
\end{alltt}
\begin{verbatim}
##    n=10^2    n=10^3    n=10^4    n=10^5 
## 0.3015113 0.3471607 0.3409914 0.3428752
\end{verbatim}
\end{kframe}
\end{knitrout}

Los resultados se muestran en el cuadro \ref{tab:sd} reflejando cómo los sistemas varían entre ellos.

\begin{table}[ht]
  \centering
  \begin{tabular}{|c|c|}
    \hline
    $n$& Desviación estándar \\ \hline
    $10^{2}$ & $0.3015113$ \\ \hline
    $10^{3}$ & $0.3471607$ \\ \hline
    $10^{4}$ & $0.3409914$\\ \hline
    $10^{5}$ & $0.3428752$\\ \hline
  \end{tabular}
  \caption{Desviación estándar para cada $n$.}
  \label{tab:sd}
\end{table}

\subsection{Find the 95 \% CI’s for each $n$. Do the confidence intervals contain the actual reliability value from item \ref{subsec:p6-b}?}

Teniendo en cuenta:

\[
CI = \bar{X} \pm c \times \frac{s}{\sqrt{n}}
\]

Se puede volver a modificar nuevamente la función \lstinline|simulate_system_reliability()| para que también retorne el intervalo superior e inferior, esto teniendo en cuenta la formula que se viene manejando durante todo el taller, por lo tanto, el código sería:


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{simulate_system_reliability} \hlkwb{<-} \hlkwa{function}\hldef{(}\hlkwc{n}\hldef{,} \hlkwc{p}\hldef{) \{}
  \hldef{reliabilities} \hlkwb{<-} \hlkwd{numeric}\hldef{(n)}
  \hlkwa{for} \hldef{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hldef{n) \{}
    \hldef{reliabilities[i]} \hlkwb{<-} \hlkwd{calculate_reliability}\hldef{(p)}
  \hldef{\}}

  \hldef{mean_val} \hlkwb{<-} \hlkwd{mean}\hldef{(reliabilities)}
  \hldef{sd_val} \hlkwb{<-} \hlkwd{sd}\hldef{(reliabilities)}
  \hldef{error_margin} \hlkwb{<-} \hlnum{1.96} \hlopt{*} \hldef{(sd_val} \hlopt{/} \hlkwd{sqrt}\hldef{(n))}  \hlcom{# 95% CI}

  \hlkwd{return}\hldef{(}\hlkwd{c}\hldef{(}\hlkwc{mean} \hldef{= mean_val,}
           \hlkwc{lower} \hldef{= mean_val} \hlopt{-} \hldef{error_margin,}
           \hlkwc{upper} \hldef{= mean_val} \hlopt{+} \hldef{error_margin))}
\hldef{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

Se ha agregado una variable de \lstinline|mean_val| y el \lstinline|error_margin| para luego entre ellas restar y sumar, respectivamente, para obtener el intervalo de confianza completo. Ahora, se puede volver a correr la simulación e imprimir la salida.


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Run simulation for each n}
\hldef{results} \hlkwb{<-} \hlkwd{t}\hldef{(}\hlkwd{sapply}\hldef{(}\hlkwd{c}\hldef{(}\hlnum{10}\hlopt{^}\hlnum{2}\hldef{,} \hlnum{10}\hlopt{^}\hlnum{3}\hldef{,} \hlnum{10}\hlopt{^}\hlnum{4}\hldef{,} \hlnum{10}\hlopt{^}\hlnum{5}\hldef{),}
                  \hlkwa{function}\hldef{(}\hlkwc{n}\hldef{)} \hlkwd{simulate_system_reliability}\hldef{(n, p)))}

\hlkwd{rownames}\hldef{(results)} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlsng{"n=10^2"}\hldef{,} \hlsng{"n=10^3"}\hldef{,} \hlsng{"n=10^4"}\hldef{,} \hlsng{"n=10^5"}\hldef{)}

\hlcom{# Print result as a table}
\hlkwd{print}\hldef{(}\hlkwd{round}\hldef{(results,} \hlnum{5}\hldef{))}
\end{alltt}
\begin{verbatim}
##           mean   lower   upper
## n=10^2 0.15000 0.07966 0.22034
## n=10^3 0.12200 0.10170 0.14230
## n=10^4 0.13630 0.12957 0.14303
## n=10^5 0.13569 0.13357 0.13781
\end{verbatim}
\end{kframe}
\end{knitrout}

Recordando que el valor de la sección \ref{subsec:p6-b} es 0.136, y el intervalo quedó como:
 
\[
[0.1335674, 0.1378126 ]
\]

Por lo tanto, el valor que se encontró anteriormente sí cae en el intervalo de confianza.


\section{Reading assignment}

Se optó por buscar una opción gratuita del libro en PDF, esto debido a que la versión que se encuentra en la Tadeo es muy incómoda por leer, el PDF se puede encontrar libre de descargar \href{https://www.academia.edu/114463674/Practical_Statistics_for_Data_Scientists_50_Essential_Concepts_Using_R_and_Python_by_Peter_Bruce_Andrew_Bruce_Peter_Gedeck}{\textbf{aquí}}. Se han tomado las siguientes ideas mientras se hacía la lectura del libro:

\begin{itemize}
  \item Las muestras que se deben elegir de un población deben ser representativas y aleatorias, porque pueden pasar casos como el de las elecciones de Landon y Roosevelt, creando un sesgo para el \textit{dataset}.
  \item Lo que se entiende por un muestreo estratificado es seleccionar nuestros datos por grupos. Por ejemplo, si quiero saber los ingresos de los habitantes de Bogotá, no me puedo tomar solo muestras de la gente estrato 6, porque me quedará sesgado el análisis y voy a concluir que todos los habitantes de Bogotá ganan mucho dinero. En cambio, tengo que reconocer cómo están segmentados los estratos sociales en la ciudad; 10\% para estrato 6, 20\% para el 5, etc.\footnote{Datos inventados por los autores} De esos grupo ahora se toman mustras aleatorias y así hemos reducido el sesgo del experimento.
  \item Las diferencias entre $\bar{x}$ y $\mu$ están en que la información sobre muestras es observada, y la información sobre poblaciones grandes es a menudo inferida de muestras más pequeñas.
  \item ``Si toturas a los datos por un tiempo largo, tarde o temprano confesarán''.
  \item Especifica una hipótesis y recolectar datos seguido de una aleatoriedad y principios de muestreo aleatorio asegura reducir los sesgos.
  \item El teorema central del límite tiene mucha importancia en los libros clásicos de estadística pero no es tan \textit{central} en la práctica de la ciencia de datos.
  \item El error estándar es una métrica que mide la variabilidad de la distribución muestreada para una estadística. A medida que el tamaño de la muestra aumenta, el error estándar disminuye.
  \item La desviación estándar mide la variabilidad de puntos de datos individuales y el error estándar mide la variabilidad de una muestra.
  \item Una muestra \textit{bootstrap} es aquella que se toma con reemplazo de un conjunto de datos observado.
  \item Remuestro es el proceso de tomar repetidamente muestras de los datos observados, incluyendo procedimientos como \textit{bootstrap} y permutaciones.
  \item Pasos para un algoritmo \textit{Bootstrap}:
        \begin{enumerate}
          \item Obtener un valor de muestra, guardarlo, y luego reemplazarlo.
          \item Repetir $n$ veces.
          \item Obtener la media de los $n$ valores remuestreados.
          \item Repetir los pasos 1 a 3 $R$ veces. 
          \item Usar los $R$ resultados para:
                \begin{enumerate}
                  \item Calcular la desviación estándar.
                  \item Producir un histograma o un \textit{boxplot}.
                  \item Encontrar el intervalo de confianza.
                \end{enumerate}
        \end{enumerate}
  \item El término remuestreo se refiere a hacer procedimientos de permutaciones, donde múltiples muestras son combinadas y el muestro puede ser hecho sin reemplazo. El término \textit{boostrapping} siempre ímplica hacer muestro con reemplazo.
  \item La mayoría de los datos no se distribuyen de manera normal y la distribución Gaussiana está sobrevalorada.
  \item La distribución $t$ es como una distribución normal pero con colas más anchas.
  \item La distribución binomial es muy usada cuando se trata de una salida de sí/no. Se puede adaptar a varios conceptos; funciona/no funciona, comprar/no comprar, etc.
\end{itemize}

\subsection{Include in your submission an exploration of the dataset \textit{loans\_income.csv} by replicating some of the codes of the sections: \textit{Sampling Distribution of a Statistic} , \textit{Bootstrap}, or \textit{Confidence Intervals}.}

\subsubsection{\textit{Sampling Distribution onf a Statistic}}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hldef{(ggplot2)}

\hlcom{# Lectura del dataset}
\hldef{loans_income} \hlkwb{<-} \hlkwd{read.csv}\hldef{(}\hlsng{"loans_income.csv"}\hldef{)}
\hldef{loans_income} \hlkwb{<-} \hldef{loans_income[[}\hlkwd{colnames}\hldef{(loans_income)]]}

\hlcom{# Tomar una muestra de una variable aleatoria simple. }
\hldef{samp_data} \hlkwb{<-} \hlkwd{data.frame}\hldef{(}\hlkwc{income}\hldef{=}\hlkwd{sample}\hldef{(loans_income,} \hlnum{1000}\hldef{),}
                        \hlkwc{type} \hldef{=} \hlsng{'data_dist'}\hldef{)}

\hlcom{# Tomar una muestra de medias de 5 valores}
\hldef{samp_mean_05} \hlkwb{<-} \hlkwd{data.frame}\hldef{(}\hlkwc{income} \hldef{=} \hlkwd{tapply}\hldef{(}\hlkwd{sample}\hldef{(loans_income,} \hlnum{1000}\hlopt{*}\hlnum{5}\hldef{),}
                \hlkwd{rep}\hldef{(}\hlnum{1}\hlopt{:}\hlnum{1000}\hldef{,} \hlkwd{rep}\hldef{(}\hlnum{5}\hldef{,} \hlnum{1000}\hldef{)),} \hlkwc{FUN}\hldef{=mean),} \hlkwc{type}\hldef{=}\hlsng{'mean_of_5'}\hldef{)}

\hlcom{# Tomar una muestra de medias de 20 valores }
\hldef{samp_mean_20} \hlkwb{<-} \hlkwd{data.frame}\hldef{(}\hlkwc{income} \hldef{=} \hlkwd{tapply}\hldef{(}\hlkwd{sample}\hldef{(loans_income,} \hlnum{1000}\hlopt{*}\hlnum{20}\hldef{),}
                  \hlkwd{rep}\hldef{(}\hlnum{1}\hlopt{:}\hlnum{1000}\hldef{,} \hlkwd{rep}\hldef{(}\hlnum{20}\hldef{,} \hlnum{1000}\hldef{)),} \hlkwc{FUN}\hldef{=mean),} \hlkwc{type}\hldef{=}\hlsng{'mean_of_20'}\hldef{)}

\hlcom{# Unir los data frames y convertir la columna type como factor, es decir, }
\hlcom{# una categoría}
\hldef{income} \hlkwb{<-} \hlkwd{rbind}\hldef{(samp_data, samp_mean_05, samp_mean_20)}
\hldef{income}\hlopt{$}\hldef{type} \hlkwb{=} \hlkwd{factor}\hldef{(income}\hlopt{$}\hldef{type,} \hlkwc{levels}\hldef{=}\hlkwd{c}\hldef{(}\hlsng{'data_dist'}\hldef{,} \hlsng{'mean_of_5'}\hldef{,}
        \hlsng{'mean_of_20'}\hldef{),} \hlkwc{labels}\hldef{=}\hlkwd{c}\hldef{(}\hlsng{'Data'}\hldef{,} \hlsng{'Mean of 5'}\hldef{,} \hlsng{'Mean of 20'}\hldef{))}

\hlcom{# Graficar}
\hlkwd{ggplot}\hldef{(income,} \hlkwd{aes}\hldef{(}\hlkwc{x}\hldef{=income))}\hlopt{+}\hlkwd{geom_histogram}\hldef{(}\hlkwc{bins}\hldef{=}\hlnum{40}\hldef{)}\hlopt{+}\hlkwd{facet_grid}\hldef{(type} \hlopt{~} \hldef{.)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-12-1} 
\end{knitrout}


\subsubsection{\textit{Bootstrap}}

El código anterior utiliza tal cual cómo aparece el ejemplo en el libro, solo que aquí se carga el \textit{dataset} a la variable \lstinline|loans_income|. Después crea tres muestras diferentes; \lstinline|samp_data| que toma 1000 valores aleatorios directamente del \textit{dataset} y los guarda con la etiqueta ``data\_dist''; \lstinline|samp_mean_05| toma una muestra de 5000 valores (la operación que se hace son 1000 grupos de 5), calcula el promedio de cada grupo de 5, y se obtienen 1000 promedios; \lstinline|samp_mean_20|, es parecido al anterior pero con grupos de valores de 20, se obtienen 1000 promedios de 20 valores cada uno. Después de tomar las muestras se combinan los datos en un solo \textit{dataframe} \lstinline|income| y después convierte la columna \lstinline|type| en un factor categórico con etiquetas que facilitan la lectura. Por último, se grafican los histogramas, cada uno con 40 barras y se utiliza \lstinline|face_grid(type ~ .)| para mostrar tres gráficos separados.

Se va a utilizar el paquete \texttt{boot} que permite realizar las operaciones para un muestreo \textit{bootstrap} replicando 1000 veces la función \lstinline|stat_fun()| al \textit{dataset} \lstinline|stat_fun|

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hldef{(boot)}
\hldef{stat_fun} \hlkwb{<-} \hlkwa{function}\hldef{(}\hlkwc{x}\hldef{,} \hlkwc{idx}\hldef{)} \hlkwd{median}\hldef{(x[idx])}
\hldef{boot_obj} \hlkwb{<-} \hlkwd{boot}\hldef{(loans_income,} \hlkwc{R}\hldef{=}\hlnum{1000}\hldef{,} \hlkwc{statistic}\hldef{=stat_fun)}
\hldef{boot_obj}
\end{alltt}
\begin{verbatim}
## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = loans_income, statistic = stat_fun, R = 1000)
## 
## 
## Bootstrap Statistics :
##     original   bias    std. error
## t1*    62000 -82.5945    222.1515
\end{verbatim}
\end{kframe}
\end{knitrout}

La función \lstinline|stat_fun()| recibe un vector \lstinline|x| (los datos originales) y otro vector \lstinline|idx| (índices de muestra aleatoria con reemplazo generados por el \textit{bootstrap}), y devuelve la mediana de los valores muestreados. Después se ejecuta el \textit{bootstrap} mediante la función \lstinline|boot()| que toma el \textit{dataset} \lstinline|loans_income|, genera 1000 muestras con reemplazo, para cada muestra calcula la mediana usando la función previamente definida. Por último, muestra el valor original de la mediana, las 1000 replicaciones (medianas \textit{bootstrap}) e información de las muestras como el bias y el error estándar.

\subsubsection{\textit{Confidence Intervals}}

Se utiliza el código que se encuentra en el repositorio del libro.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{set.seed}\hldef{(}\hlnum{5}\hldef{)}
\hlkwd{set.seed}\hldef{(}\hlnum{7}\hldef{)}
\hldef{sample20} \hlkwb{<-} \hlkwd{sample}\hldef{(loans_income,} \hlnum{20}\hldef{)}
\hldef{sampleMean} \hlkwb{<-} \hlkwd{mean}\hldef{(sample20)}

\hldef{stat_fun} \hlkwb{<-} \hlkwa{function}\hldef{(}\hlkwc{x}\hldef{,} \hlkwc{idx}\hldef{)} \hlkwd{mean}\hldef{(x[idx])}
\hldef{boot_obj} \hlkwb{<-} \hlkwd{boot}\hldef{(sample20,} \hlkwc{R}\hldef{=}\hlnum{500}\hldef{,} \hlkwc{statistic}\hldef{=stat_fun)}
\hldef{boot_ci} \hlkwb{<-} \hlkwd{boot.ci}\hldef{(boot_obj,} \hlkwc{conf}\hldef{=}\hlnum{0.9}\hldef{,} \hlkwc{type}\hldef{=}\hlsng{'basic'}\hldef{)}
\hldef{X} \hlkwb{<-} \hlkwd{data.frame}\hldef{(}\hlkwc{mean}\hldef{=boot_obj}\hlopt{$}\hldef{t)}
\hldef{ci90} \hlkwb{<-} \hldef{boot_ci}\hlopt{$}\hldef{basic[}\hlnum{4}\hlopt{:}\hlnum{5}\hldef{]}
\hldef{ci} \hlkwb{<-} \hlkwd{data.frame}\hldef{(}\hlkwc{ci}\hldef{=ci90,} \hlkwc{y}\hldef{=}\hlkwd{c}\hldef{(}\hlnum{9}\hldef{,} \hlnum{11}\hldef{))}
\hldef{ci}
\end{alltt}
\begin{verbatim}
##         ci  y
## 1 51643.09  9
## 2 65262.95 11
\end{verbatim}
\begin{alltt}
\hlkwd{ggplot}\hldef{(X,} \hlkwd{aes}\hldef{(}\hlkwc{x}\hldef{=mean))} \hlopt{+}
  \hlkwd{geom_histogram}\hldef{(}\hlkwc{bins}\hldef{=}\hlnum{40}\hldef{,} \hlkwc{fill}\hldef{=}\hlsng{'#AAAAAA'}\hldef{)}\hlopt{+}
  \hlkwd{geom_vline}\hldef{(}\hlkwc{xintercept}\hldef{=sampleMean,} \hlkwc{linetype}\hldef{=}\hlnum{2}\hldef{)} \hlopt{+}
  \hlkwd{geom_path}\hldef{(}\hlkwd{aes}\hldef{(}\hlkwc{x}\hldef{=ci,} \hlkwc{y}\hldef{=}\hlnum{10}\hldef{),} \hlkwc{data}\hldef{=ci,} \hlkwc{size}\hldef{=}\hlnum{2}\hldef{)} \hlopt{+}
  \hlkwd{geom_path}\hldef{(}\hlkwd{aes}\hldef{(}\hlkwc{x}\hldef{=ci90[}\hlnum{1}\hldef{],} \hlkwc{y}\hldef{=y),} \hlkwc{data}\hldef{=ci,} \hlkwc{size}\hldef{=}\hlnum{2}\hldef{)} \hlopt{+}
  \hlkwd{geom_path}\hldef{(}\hlkwd{aes}\hldef{(}\hlkwc{x}\hldef{=ci90[}\hlnum{2}\hldef{],} \hlkwc{y}\hldef{=y),} \hlkwc{data}\hldef{=ci,} \hlkwc{size}\hldef{=}\hlnum{2}\hldef{)} \hlopt{+}
  \hlkwd{annotate}\hldef{(}\hlsng{'text'}\hldef{,} \hlkwc{x}\hldef{=sampleMean,} \hlkwc{y}\hldef{=}\hlnum{20}\hldef{,} \hlkwc{label}\hldef{=}\hlsng{'Sample mean'}\hldef{,} \hlkwc{size}\hldef{=}\hlnum{6}\hldef{)} \hlopt{+}
  \hlkwd{annotate}\hldef{(}\hlsng{'text'}\hldef{,} \hlkwc{x}\hldef{=sampleMean,} \hlkwc{y}\hldef{=}\hlnum{8}\hldef{,} \hlkwc{label}\hldef{=}\hlsng{'90% interval'}\hldef{,} \hlkwc{size}\hldef{=}\hlnum{6}\hldef{)} \hlopt{+}
  \hlkwd{theme_bw}\hldef{()} \hlopt{+}
  \hlkwd{labs}\hldef{(}\hlkwc{x} \hldef{=} \hlsng{''}\hldef{,} \hlkwc{y}\hldef{=}\hlsng{'Counts'}\hldef{)}
\end{alltt}


{\ttfamily\noindent\color{warningcolor}{\#\# Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\\\#\# i Please use `linewidth` instead.\\\#\# This warning is displayed once every 8 hours.\\\#\# Call `lifecycle::last\_lifecycle\_warnings()` to see where this warning was\\\#\# generated.}}\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-14-1} 
\end{knitrout}

El código no genera la misma salida de la figura que se encuentra en el libro, esto debido a que se replicó el que está disponible en GitHub y dentro del archivo del \textit{script} hay un comentario diciendo que la figura no está disponible, esto se puede mostrar como evidencia en la figura \ref{fig:GH}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{img/Punto7.png}
  \caption{\label{fig:GH} \textit{Script} del libro \textit{Practical statistics for data scientists: 50+ essential concepts using R and Python}\cite{bruce2020practical}.}
\end{figure}

Por otra parte, se muestra una advertencia por el estilo de la figura, el parámetro \lstinline|size| ha sido deprecado, esto quiere decir que esta edición del libro se realizó con una versión de \lstinline|ggplot2| mucho más vieja que la que está actualmente.




\printbibliography


\end{document}
